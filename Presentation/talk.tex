\documentclass[compress,11pt,xcolor=svgnames,aspectratio=169]{beamer}
\usetheme{Esiwace}
\usefonttheme[onlysmall]{structurebold}

%\usepackage{caption}
%\captionsetup{labelformat=empty, format=plain, labelsep=none,textfont=footnotesize}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{eurosym}
%\usepackage{ulem}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{pgfgantt}
\usepackage{comment}
\usepackage{tikz}
% \usepackage[backend=bibtex]{biblatex}
% \bibliography{io} % \footfullcite{jones00}
% \usepackage[numbers]{natbib}
\usepackage[absolute,overlay]{textpos}
\usepackage{varwidth}
\usepackage{cancel}
\usepackage{ulem}

\newcommand{\lr}[1]{\textcolor{cyan}{LR: #1}}
\setbeamercolor{bibliography item}{parent=palette primary}

\newcommand{\sectionIntro}{
\begin{frame}{Outline}
  \begin{centering}
  {\scriptsize
  \tableofcontents[currentsection,hideothersubsections]%,subsectionstyle=hide/hide/hide
  }
  \end{centering}
\end{frame}
}

\newcommand{\sectionIntroHidden}{
\begin{frame}{Outline}
  \begin{centering}
  {\scriptsize
  \tableofcontents[currentsection,subsectionstyle=hide/hide/hide]
  }
  \end{centering}
\end{frame}
}

\definecolor{gold}{rgb}{0.83, 0.69, 0.22}

\makeatletter
\renewcommand{\itemize}[1][]{%
  \beamer@ifempty{#1}{}{\def\beamer@defaultospec{#1}}%
  \ifnum \@itemdepth >2\relax\@toodeep\else
    \advance\@itemdepth\@ne
    \beamer@computepref\@itemdepth% sets \beameritemnestingprefix
    \usebeamerfont{itemize/enumerate \beameritemnestingprefix body}%
    \usebeamercolor[fg]{itemize/enumerate \beameritemnestingprefix body}%
    \usebeamertemplate{itemize/enumerate \beameritemnestingprefix body begin}%
    \list
      {\usebeamertemplate{itemize \beameritemnestingprefix item}}
      {\def\makelabel##1{%
          {%
            \hss\llap{{%
                \usebeamerfont*{itemize \beameritemnestingprefix item}%
                \usebeamercolor[fg]{itemize \beameritemnestingprefix item}##1}}%
          }%
        }%
      }
  \fi%
  \beamer@cramped%
  \justifying% NEW
  %\raggedright% ORIGINAL
  \beamer@firstlineitemizeunskip%
}
\makeatother

\tcbuselibrary{raster}

\DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg}
\graphicspath{{./fig/}}

\title[Input/Output and Middleware -- Talk Session]{2020 Summer School on Effective HPC for Climate and Weather \\[0.5cm] Input/Output and Middleware}
\author[Pedro, Kunkel]{Luciana Pedro, Julian Kunkel
}
\institute[WP4 Team]{Department of Computer Science, University of Reading}
\date{18 June 2020}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[plain]
    \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{withoutheadline}
\begin{frame}{Outline}
    \begin{centering}
    {\tiny
    \tableofcontents[hideallsubsections]
    }
    \end{centering}
    \disclaimer
\end{frame}
\end{withoutheadline}

% Input/Output and Middleware
% Climate and weather research is typically data-intensive and applications must utilise input/output efficiently. Often, a user struggles to assess observed performance leading to superflux attempts to tune the application and optimise performance in a wrong layer of the stack. The content of this session is twofold. Firstly, we discuss storage layers focusing on the NetCDF middleware and provide a performance model that aids users to identify inefficient I/O. Secondly, we introduce the NetCDF Climate and Forecast (CF) conventions that are often used as a standard to exchange data.

\begin{frame}[fragile]{Learning Objectives -- Talk}

{\footnotesize

\begin{itemize}
\setlength\itemsep{0.4cm}
  \item Discuss challenges for data-driven research (Section \nameref{sec:intro})
  \item Describe the role of middleware and file formats (Section \nameref{sec:io-sol})
  \item Identify typical I/O performance issues and their causes (Section \nameref{sec:io-sol})
  \item Apply performance models to assess and optimize the application I/O performance (Section \nameref{sec:io-perf})
  \item Design a data model for NetCDF/CF (Section \nameref{sec:netcdf})
  \item Implement an application that utilizes parallel I/O to store and analyze data (Section \nameref{sec:pio})
  \item Describe ongoing research activities in high-performance storage (Section \nameref{sec:res})
\end{itemize}

}

\end{frame}

\begin{frame}[fragile]{Learning Objectives -- Lab}

{\footnotesize

\begin{itemize}
\setlength\itemsep{1cm}
  \item Execute programs in C that read and write NetCDF files in a metadata-aware manner
  \item Analyze, manipulate and visualise NetCDF data
  \item Implement an application that utilizes parallel I/O to store and analyze data
\end{itemize}

}

\end{frame}

\section{Introduction}
\sectionIntro
\label{sec:intro}

\subsection{I/O Bottleneck}

\begin{frame}[fragile]{I/O Bottleneck -- Titan}

\begin{center}
\includegraphics[scale=0.45]{fig/bottleneck}
\end{center}

\nocite{sensei-sc17}

\end{frame}

\begin{frame}[fragile]{I/O Bottleneck -- Mistral}

\begin{itemize}
\setlength\itemsep{0.4cm}
\item Predict processor performance growth by 20x each generation ($\sim$5 years).
\item Storage throughput/capacity improves by just 6x.
\item Costs and performance come together.
\end{itemize}

\vspace*{-1.6cm}

\begin{center}
\begin{tabular}{cc}
& { \footnotesize Real Values -- 2018} \\
\raisebox{1cm}{\includegraphics[scale=0.4]{fig/bottleneck-dkrz}} &
\raisebox{0.6cm}{\includegraphics[scale=0.45]{fig/mistral}}
\end{tabular}
\end{center}

\nocite{ESSAASOEKK14}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.7]{fig/FoldersVsMeta}
\end{center}

\end{frame}

\subsection{Data-driven Research}

\begin{frame}[fragile]{Data-driven Research}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item \textbf{Data-driven Research} is the science of letting data tell us what we are looking for.
    \begin{itemize}
      \item \textbf{Database Management} is the science of efficiently storing and retrieving data.
      \item \textbf{Data Mining} is the science of discovering hidden correlations in data.
    \end{itemize}

  \item In HPC, the concerns of \textbf{storage} and \textbf{computing} are traditionally separated and optimised independently from each other and the needs of the end-to-end user.

  \item Workflows composed of data, computing, and communication-intensive tasks should drive interfaces and hardware configurations to best support the programming models.

  \item Data-driven workflows may benefit from the explicit and simultaneous use of a locally heterogeneous set of computing and storage technologies.

%  \item Many processes still require experts. For example, porting a workflow from one system to another still requires adjusting runtime parameters of applications and deciding on how data is managed.

\end{itemize}

\nocite{01403233}

\nocite{JSFI309}

\end{frame}

\section{Input/Output}
\sectionIntro
\label{sec:io}

\begin{frame}[fragile]{Input/Output}

\begin{itemize}
\setlength\itemsep{0.3cm}

    \item Input/Output (I/O) is simply data migration.

    \begin{itemize}
      \item Memory $\Leftrightarrow$ Disk
    \end{itemize}

    \item I/O is a very expensive operation!

%    \begin{itemize}
%      \item Interactions with data in memory and on disk.
%    \end{itemize}

    \item How is I/O performed?

    \begin{itemize}

      \item I/O Pattern

      \begin{itemize}
        \item Number of processes and files.
        \item Characteristics of file access.
      \end{itemize}

    \end{itemize}

    \item Where is I/O performed?

    \begin{itemize}
      \item Characteristics of the computational system.
      \item Characteristics of the file system.
    \end{itemize}

\end{itemize}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Performance}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item There is no ``One Size Fits All'' solution to the I/O problem.

  \item Bottlenecks in performance can occur in many locations.

  \begin{itemize}
    \item Application and/or file system.
  \end{itemize}

  \item Many I/O patterns work well for some range of parameters.

  \item Going to extremes with an I/O pattern will typically lead to problems.

  \item {\color{gold}\textbf{Golden Rule:}} Increase performance by decreasing the number of I/O operations and increasing the size of each operation.

\end{itemize}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Types}

\begin{center}
\includegraphics[scale=0.35]{io-types}
\end{center}

\end{frame}

\begin{frame}[fragile]{I/O Access Patterns}

\begin{center}
\includegraphics[scale=0.35]{io-patterns}
\end{center}

\end{frame}

\begin{frame}[fragile]{File Striping}

\vspace*{-0.7cm}

\begin{center}
\includegraphics[scale=0.35]{fig/file-striping}
\end{center}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Stack}

{\tiny

\begin{columns}
\begin{column}{0.38\textwidth}
\begin{block}{Application}
\begin{itemize}
\item Weather forecasts.
\item Climate simulations, impacts, predictions and projections.
\item Decisions on emission reductions.
\item Strategies for housing, cities, farming, coastal defenses and other parts of society.
\end{itemize}
\end{block}
\begin{block}{High Level I/O Library}
\begin{itemize}
\item Match storage abstraction to domain.
\item Provide self-describing, structured files.
\item Map to middleware interface.
\item Implement further optimizations.
\end{itemize}
\end{block}
\end{column}
\begin{column}{0.24\textwidth}
\begin{center}
\includegraphics[scale=0.8]{fig/io-stack}
\end{center}
\end{column}
\begin{column}{0.38\textwidth}
\begin{block}{I/O Middleware}
\begin{itemize}
\item Match the programming model (e.g. MPI).
\item Facilitate concurrent access by groups of processes.
\item Expose a generic interface.
\item Efficiently map middleware operations into operations in the Parallel File System.
\end{itemize}
\end{block}
\begin{block}{Parallel File System}
\begin{itemize}
\item Manage storage hardware.
\item In the I/O software stack, focus on concurrent, independent access.
\item Publish an interface that middleware can use effectively.
\end{itemize}
\end{block}
\end{column}
\end{columns}

}

\nocite{esiwace}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Stack -- \lr{Alternative Slide}}

\begin{center}
\includegraphics[scale=0.7]{fig/stack2}
\end{center}

\end{frame}

\end{comment}

\begin{frame}[fragile]{I/O Problems}

\begin{itemize}
\setlength\itemsep{0.7cm}

\item Not enough I/O capacity on current HPC systems, and the trend is getting worse.

\item If there is not enough I/O, you cannot write data to storage, so you can not analyze it.
    \begin{itemize}
        \item Lost science!
    \end{itemize}

\item Missing opportunity of doing better science (analysis) when have access to full spatiotemporal resolution data.

\item Energy consumption: it costs a lot of power to write data to disk.

\end{itemize}

\nocite{sensei-sc17}

\end{frame}

\begin{frame}[fragile]{Challenges in Domain of Climate and Weather}

\begin{itemize}
\setlength\itemsep{0.2cm}

\item High data volume and velocity

\item Data management practice does not scale

  \begin{itemize}
      \item E.g., hierarchical namespaces does not reflect use cases
      \item Scientists spend quite some time to define the namespace
  \end{itemize}

\item Suboptimal performance (and performance portability) of data formats

  \begin{itemize}
    \item Tuning for NetCDF, HDF5 and GRIB necessary
    \item Scientists worry about interoperability
  \end{itemize}

\item Data conversion is often needed

  \begin{itemize}
    \item Between formats such as NetCDF and GRIB
    \item To combine data from multiple experiments, time steps, etc.
  \end{itemize}

\item External data services to share data in the community

  \begin{itemize}
    \item (Scientific) metadata is provided by databases
  \end{itemize}

\end{itemize}

\end{frame}

\section{I/O Solutions}
\sectionIntro
\label{sec:io-sol}

\begin{frame}[fragile]{I/O Solutions}

\begin{itemize}

\item As we are moving towards exascale, the gap between computing power and I/O bandwidth will
widen and researchers are looking for solutions to tackle this problem.\\[0.4cm]

\item There are essentially three lines of research:\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

      \item at hardware level,
      \item at middleware level,
      \item and at application level.

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\subsection{Hardware Level}

\begin{frame}[fragile]{Hardware Level}

\begin{itemize}

    \item Non-volatile memory (NVM)\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

        \item Non-volatile memory (NVM) is a type of computer memory that can retrieve stored information even after having been power cycled.

        \item The capabilities of NVM (i.e., capacity, bandwidth, energy consumption) are somewhere in-between main memory and persistent storage, thus it is often used as a ``caching'' solution between these two layers.

        \item Examples of non-volatile memory include flash memory, read-only memory (ROM), ferroelectric RAM, most types of magnetic computer storage devices (e.g. hard disk drives, floppy disks, and magnetic tape), optical discs, and early computer storage methods such as paper tape and punched cards.

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Hardware Level}

\begin{itemize}

    \item Burst buffer (BB)\\[0.4cm]

      \begin{itemize}
      \setlength\itemsep{0.5cm}

      \item Burst buffer (BB) is a fast and intermediate storage layer positioned between the front-end computing processes and the backend storage systems.

      \item HPC applications often show bursty I/O behavior (i.e., all processes read/write at the same time) and burst buffers help to absorb these workloads.

      \item Burst buffer is built from arrays of high-performance storage devices, such as NVRAM and SSD.

      \end{itemize}

\begin{comment}

      \begin{center}
      \begin{tabular}{ccccc}
      \raisebox{1cm}{NVRAM} &
      \includegraphics[scale=0.25]{fig/nvram} & $\qquad$ &
      \includegraphics[scale=0.24]{fig/ssd} &
      \raisebox{1cm}{
        \begin{tabular}{c}
        SSD \\
        (on top of \\
        a hard drive)
        \end{tabular}
      }
      \end{tabular}
      \end{center}

\end{comment}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{Hardware Level \lr{(Keep it?)}}

\begin{itemize}

      \item Multi-layer Storage Hierarchy (Examples)\\[0.4cm]

        \begin{itemize}
        \setlength\itemsep{0.6cm}

        \item Attached SSDs to compute nodes to aggregate many small I/O requests into few larger ones and/or to compute nodes to speed-up MPI-IO.

        \item Multi-layer storage hierarchy with NVM, SSDs, and different types of hard disks. % drives.

        \item Fast Forward Storage and IO (FFSIO), SAGE, Distributed Application Object Store (DAOS), Post-Petascale File System (PPFS), Scalable Object-Centric Metadata Management (SoMeta), Extensible Metadata Provider for Extreme-Scale Scientific Simulations (EMPRESS), Týr

        \item ECP [16], Fast-Forward [44], ADIOS [72], HDF VOL [29], ESiWACE [20], NEXTGenIO [69] and SAGE [78]

        \item Blue gene active storage, Dash

        \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Middleware -- Definition}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item Middleware is software occupying a middle position between application programs and operating systems.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/middleware2}
\end{center}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Middleware}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item Middleware is in the middle of the vertical stack, between the application programs and the operating system.

  \item Viewed horizontally rather than vertically, middleware is also in the middle of interactions between different application programs (possibly even running on different computer systems), because it provides mechanisms to support controlled interaction through coordination, persistent storage, naming, and communication.

  \item Middleware provide a more sophisticated form of persistent storage than the standard supported by most operating systems.

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Middleware -- Examples}

\begin{itemize}
\setlength\itemsep{0.6cm}

\item Common middleware examples include relational database systems, application server middleware, message-oriented middleware, web middleware, and transaction-processing monitors.

  \begin{itemize}
  \setlength\itemsep{0.4cm}

  \item Relational Database Management Systems (RDBMS): Oracle Database\footnote{\tiny \url{https://www.oracle.com/database/technologies/}} and PostgreSQL\footnote{\tiny \url{https://www.postgresql.org/}}.

  \item Messaging Systems: IBM MQ\footnote{\tiny \url{https://www.ibm.com/uk-en/products/mq}}, Jakarta Messaging API\footnote{\tiny \url{https://projects.eclipse.org/projects/ee4j.jms}}, and Java RMI (Remote Method Invocation)\footnote{\tiny \url{https://www.oracle.com/java/technologies/javase/remote-method-invocation-home.html}}.

  \item \lr{Input/Output Systems: ESDM}

  \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item Operating systems and middleware have much in common.

  \item Both are software used to support other software, such as the application programs you run.

  \item Both provide a similar range of services centered around \textit{controlled interaction}.

  \item \textbf{Controlled Interaction} is the interaction between concurrent computations.\\[0.3cm]

  \begin{itemize}
  \setlength\itemsep{0.4cm}
    \item On the same system -- As between your email program and your word processor.
    \item Across time -- As between your word processor before your trip and your word processor after your trip.
    \item Across space -- As between your email program and your service provider's email server.
  \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item Like an operating system, middleware may enforce rules designed to keep the computations from interfering with one another. An example is the rule that only one computation may modify a shared data structure at a time.

  \item Like an operating system, middleware may bring computations at different times into contact through persistent storage and may support interaction between computations on different computers by providing network communication services.

  \item However, operating systems and middleware are not the same.

  \item They rely upon different underlying providers of lower-level services.

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item An operating system provides the services in its API by making use of the features supported by the hardware.

    \begin{itemize}
    \setlength\itemsep{0.4cm}
        \item For example, it might provide API services of reading and writing \lr{named} \lr{Named Binary Tag (NBT)?}, variable-length files by making use of a disk drive's ability to read and write \lr{numbered} \lr{???}, fixed-length blocks of data.
    \end{itemize}

  \item Middleware, on the other hand, provides the services in its API by making use of the features supported by an underlying operating system.

    \begin{itemize}
    \setlength\itemsep{0.4cm}
        \item For example, the middleware might provide API services for updating relational database tables by making use of an operating system's ability to read and write files that contain the database.
        \item \lr{ESDM!}
    \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Describe the role of middleware and file formats}

\begin{itemize}

  \item File formats
    \begin{itemize}
        \item
        \item
    \end{itemize}

  \item
    \begin{itemize}
      \item
    \end{itemize}

\end{itemize}

\end{frame}

\end{comment}

\subsection{Middleware Level}

\begin{frame}[fragile]{Middleware Level}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item Solutions in I/O middleware.

    \begin{itemize}

    \item E.g., file systems, I/O interfaces.

    \end{itemize}

\item \textbf{Damaris:} Software framework that overlaps computation and I/O operations by dedicating a single core to I/O tasks.

\item \textbf{ADIOS:} I/O abstraction framework for HPC applications that enables switching between different I/O transport methods with little modification to application code and enabling integration of new I/O solutions.

\item \textbf{DeltaFS:} File systems that improves the scalability of file systems by letting compute nodes manage metadata instead of a centralized server.

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Ongoing Activity: Earth-System Data Middleware}

\begin{itemize}
\setlength\itemsep{0.4cm}

    \item ESDM provides a transitional approach towards a vision for I/O addressing\\[0.3cm]

    \begin{itemize}
    \setlength\itemsep{0.4cm}
    \item Scalable data management practice
    \item The inhomogeneous storage stack
    \item Suboptimal performance and performance portability
    \item Data conversion/merging

    \end{itemize}

    \item Part of the ESiWACE Project\footnote{Centre of Excellence in Simulation of Weather and Climate in Europe.}

\end{itemize}

\end{frame}

\subsection{Application Level}

\begin{frame}[fragile]{Application Level}

\begin{itemize}

\item In-situ analysis\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

    \item In biology and biomedical engineering, in situ means to examine the phenomenon exactly in place where it occurs (i.e., without moving it to some special medium).

    \item Rather than applications writing their raw output to storage to later be read again for post-processing (e.g., visualization, filtering, statistics), in-situ processing removes this overhead by performing the analysis directly on the same machines as where the applications run.

    \item ParaView, Dax, and Damaris/Viz are tools for large-scale in-situ visualization.

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Discussion}

\begin{itemize}
\setlength\itemsep{0.2cm}

\item No ``One Size Fits All'' solution to the storage problem and programmers must take I/O into careful consideration when developing applications.

\item Mismatch between the massive computational performance of processors and relatively limited I/O bandwidth of storage systems.

\item Three methods to alleviate this problem: new hardware technology, new I/O middleware, and application-specific solutions.

  \begin{itemize}
  \setlength\itemsep{0.2cm}

  \item Hardware technology shows promising solutions, but different systems might employ different solutions, reducing the portability and increasing the complexity. % of software.

  \item Middleware can alleviate some of this complexity with solutions such as ADIOS and ESDM.

  \item In-situ analysis is an example of how application-specific solutions can be used to improve I/O throughput and thus application performance.

  \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\section{I/O Performance}
\sectionIntro
\label{sec:io-perf}

\begin{comment}

\begin{frame}[fragile]{I/O Performance}

\begin{itemize}
\setlength\itemsep{0.8cm}

  \item There are several aspects involved in delivering high I/O performance to parallel applications, from hardware characteristics to methods that manipulate workloads to improve achievable performance.

  \item Running the same application with different I/O configurations gives the possibility to tune the I/O system according to the application access pattern.

  \item One way to predict application performance in HPC systems with different I/O configurations is by using modeling and simulation techniques.

\end{itemize}

\nocite{SOPPOAASLK13}

\end{frame}

\end{comment}

\begin{frame}[fragile]{Typical Performance Factors}

\begin{center}
\includegraphics[scale=0.44]{fig/tree-perf}
\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\subsection{I/O Performance Factors}

\begin{frame}[fragile]{I/O Performance Factor -- Access Patterns}

\vspace*{0.6cm}

\begin{itemize}
\setlength\itemsep{1cm}

  \item The access pattern describes how\\ spatial access is performed over time.

  \item With an access pattern, the I/O of a single client process can be described, but also the actual observable patterns on the I/O servers, or on a single block device.

  \item The pattern on the I/O servers is caused by all clients and defines the performance of the I/O subsystems.

\end{itemize}

%\begin{textblock}{20}(40,20)
\begin{textblock}{2}(9,3)
   \includegraphics[scale=0.5]{fig/tree-io-ac-pat}
\end{textblock}

%\begin{picture}(50,50)
%\put(10,10){\hbox{\includegraphics[scale=0.3]{fig/tree-io-ac-pat}}}
%\put(200,-300){\hbox{\includegraphics[scale=0.3]{fig/tree-io-ac-pat}}}
%\end{picture}

%\begin{center}
%\includegraphics[scale=0.6]{fig/tree-io-ac-pat}
%\end{center}

\nocite{pio-sc17}

\end{frame}

\begin{frame}[fragile]{I/O Performance Factor -- I/O Strategy}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item In general, the mechanisms introduced here are orthogonal to the hardware and the architecture of the parallel file system.

  \item On the client-side, for instance, \\
  requests could already be tuned to improve \\
  the access pattern which will be observed \\
  on the servers.

  \item Similar to optimizations in communication, \\
  these strategies could be applied on any layer involved in I/O.

\end{itemize}

\begin{textblock}{0}(9,5)
   \includegraphics[scale=0.4]{fig/tree-io-strat}
\end{textblock}

%\begin{center}
%\includegraphics[scale=0.6]{fig/tree-io-strat}
%\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\begin{frame}[fragile]{I/O Performance Factor -- Parallel File System}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item Performance of a parallel file system highly depends on its design as it provides the frame for the deployed optimization strategies.

  \item Several aspects like consistency semantics also apply to higher level interfaces like domain specific I/O libraries.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/tree-io-pfs}
\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\subsection{I/O Performance Analysis}

\begin{frame}[fragile]{I/O Performance Analysis}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Problem

    \begin{itemize}
    \item Assessing observed time for I/O is difficult.
    \item What best-case performance can we expect?
    \end{itemize}

  \item Support for performance analysis

    \begin{itemize}

    \item Models and simulation

      \begin{itemize}
      \item Trivial models: using throughput + latency
      \item PIOSimHD: MPI application + storage system simulator
      \end{itemize}

    \item Tools to capture and analyze system statistics and I/O activities

      \begin{itemize}
      \item HDTrace -- Tracing tool for parallel I/O (+ PVFS2)
      \item SIOX -- Tool to capture I/O on various levels
      \item Grafana -- Online monitoring for DKRZ (support)
      \end{itemize}

    \item Benchmarks -- On various levels, e.g., Metadata (md-workbench, IOR)

    \item Statistic model to determine likely cause based on time

    \end{itemize}

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Big Data Cluster Characteristics}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Usually commodity components
  \item Cheap (on-board) interconnect, node-local storage
  \item Communication (bisection) bandwidth between different racks is low

\end{itemize}

\begin{center}
\includegraphics[scale=0.45]{fig/arch1}
\end{center}

\end{frame}

\begin{frame}[fragile]{HPC Cluster Characteristics}

\begin{columns}

\begin{column}{0.32\textwidth}

\begin{itemize}
\setlength\itemsep{0.6cm}
  \item High-end components
  \item Extra fast interconnect, global/shared storage with dedicated servers
  \item Network provides high (near-full) bisection bandwidth.
\end{itemize}

\end{column}

\begin{column}{0.6\textwidth}
\begin{center}
\raisebox{0.1cm}{\includegraphics[scale=0.55]{fig/arch2}}
\end{center}
\end{column}

\end{columns}

\end{frame}

\begin{frame}[fragile]{Performance: Hierarchical Model \lr{Extra slide}}

\begin{center}
\includegraphics[scale=0.6]{fig/bottleneck3}
\end{center}

\end{frame}

\begin{frame}[fragile]{Hardware Performance}

\begin{block}{Computation}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item CPU performance (frequency $\times$ cores $\times$ sockets)

    \begin{itemize}
    \item E.g.: 2.5 GHz $\times$ 12 cores $\times$ 2 sockets = 60 Gcycles/s
    \item The number of cycles per operation depend on the instruction stream
    \end{itemize}

  \item Memory (throughput $\times$ channels)

    \begin{itemize}
    \item E.g.: 25.6 GB/s per DDR4 DIMM $\times$ 3
    \end{itemize}

\end{itemize}

\end{block}

\begin{block}{Communication via the network}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Throughput, e.g., 125 MiB/s with Gigabit Ethernet
  \item Latency, e.g., 0.1 ms with Gigabit Ethernet

\end{itemize}

\end{block}

\end{frame}

\begin{frame}[fragile]{I/O Performance Analysis -- A Simple Model}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Communication between different machines is limited by the network performance.

  \item \textbf{Network throughput} is the amount of data moved successfully from one place to another in a given time period. The maximum throughput depends on the number of storage servers, client nodes and their network connectivity.

  \item Users typically know:

    \begin{itemize}
%    \setlength\itemsep{0.1cm}
      \item Output/input file size.
      \item Number of nodes a job run on.
      \item Runtime of the I/O during a job (this can be obtained with simple means).
    \end{itemize}

  \item Now compute the observed throughput (\verb|tp_obs|) in MiB/s per node. If \verb|tp_obs| is much smaller than the network throughput, then there might be an I/O problem.

  \item This is a very basic model that every user should understand and apply.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Analysis -- Numeric Example}

\begin{itemize}
%\setlength\itemsep{0.4cm}
\setlength\itemsep{0.2cm}

  \item Consider the following scenario:

    \begin{itemize}
    \setlength\itemsep{0.1cm}
      \item File size: 10 GiB
      \item Number of nodes: 10
      \item Time to transfer the data: 10 seconds
    \end{itemize}

  \item Calculating the throughput in this example, one will find:\\[0.2cm]

    \begin{itemize}
    \setlength\itemsep{0.2cm}
      \item $\displaystyle \frac{10\ \text{GiB}}{10\ \text{nodes} \times 10\ \text{seconds}} = 0.1\ \text{GiB/s per node} = 100\ \text{MiB/s per node}$.
    \end{itemize}

  \item Considering that a Gigabit Ethernet network should be capable of delivering a theoretical maximum transfer of about 125 MB/s \lr{MiB/s??}, the estimate throughput is close to the optimal value.

  \item However, if you are using an Infiniband capable of delivering 6 GiB/s, then 0.1 GiB/s is a problem.  \lr{I couldn't verify 6 GiB/s. There are lots of options! So I wrote as an example.}

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Analysis -- Latency}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item \textbf{Network latency} is the time between the sending of a message and its arrival at the receiver side.

  \item \textbf{Network bandwidth} is the number of bits which can be transferred in a specific time.

  \item Because protocols like TCP have some overhead and control algorithms, the throughput is smaller than the bandwidth.

  \item Latency and bandwidth depend on the used network technology and topology.

  \item Say, for instance, you also know the number of I/O calls as well. Then, you can compute the latency per call.

    \begin{itemize}
    \setlength\itemsep{0.3cm}
      \item This information can actually be measured using Darshan, for example.
    \end{itemize}

  \item Now compute the calls per second per node and relate it to the network latency.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Improving I/O Performance}

\begin{itemize}
\setlength\itemsep{0.3cm}

\item Software and hardware tries to hide I/O penalty.

\item Caching of data:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Allow application to continue while I/O completes in the background (write-behind).
    \item Allow to aggregate multiple (small) operations into larger operations.
    \item Read data from disk before it is needed (read-ahead).
    \item \textbf{Require memory! Hiding vs. increased problem size!}.
  \end{itemize}

\item Programming:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Overlap I/O (or communication) with computation.
    \item I/O and communication comes almost for free.
    \item Optimize file format and access pattern (more complicated).
  \end{itemize}

\end{itemize}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Performance Tuning ``Rules of Thumb''}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Use collective operations when possible

  \item Use high-level libraries (e.g. HDF5 or PNetCDF) when possible

  \item A few large I/O operations are better than many small I/O operations

  \item Avoid unnecessary metadata operations, especially \texttt{stat()}

  \item Avoid writing to shared files with POSIX

  \item Avoid leaving gaps/holes in files to be written later

  \item Use tools like \textbf{Darshan} to check assumptions about behavior

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Model}

\nocite{CAPMFESDMA19}

\begin{center}
\includegraphics[scale=0.7]{fig/bottleneck3}
\end{center}

\end{frame}

\begin{frame}[fragile]{I/O Performance Model}

\nocite{CAPMFESDMA19}

\begin{center}
\includegraphics[scale=0.7]{fig/bottleneck4}
\end{center}

\end{frame}

\begin{frame}[fragile]{Assess and Optimize the Application I/O Performance}

\begin{itemize}
\setlength\itemsep{0.4cm}

    \item Develop general considerations about what influences the I/O performance

    \begin{itemize}
      \item What?
    \end{itemize}

    \item Analyze access pattern and define how it defines the performance of the I/O subsystems

    \begin{itemize}
      \item How?
    \end{itemize}

    \item Apply I/O strategies to improve the access pattern

    \begin{itemize}
      \item Which?
    \end{itemize}

    \item Identify options for the deployed optimization strategies in a specific PVFS\footnote{Parallel Virtual File System.}

    \begin{itemize}
      \item Which?
    \end{itemize}

\end{itemize}

\nocite{SOPPOAASLK13}

\end{frame}

\end{comment}

\section{NetCDF}
\sectionIntro
\label{sec:netcdf}

\subsection{Introduction}

\begin{frame}[fragile]{NetCDF}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item In a simple view, NetCDF is:

    \begin{itemize}
        \item A data model.
        \item A file format.
        \item A set of APIs and libraries for various programming languages.
    \end{itemize}

\item Together, the data model, file format, and APIs support the creation, access, and sharing of scientific data.

\item NetCDF allows the user to describe multidimensional data and include metadata which further characterizes the data.

\item NetCDF APIs are available for most programming languages used in geosciences.

\end{itemize}

\nocite{netcdf}

\end{frame}

\subsection{Common Data form Language (CDL)}

\begin{frame}[fragile]{Common Data form Language (CDL)}

\begin{itemize}
\setlength\itemsep{0.3cm}

\item The notation used to describe a NetCDF object is called CDL (network Common Data form Language), which provides a convenient way of describing NetCDF datasets.

\begin{figure}
\centering
\begin{varwidth}{\linewidth}
\tiny{

\begin{verbatim}

netcdf short {
dimensions:
  latitude = 3 ;
  longitude = 2 ;
variables:
  float sfc_temp(latitude, longitude) ;
    sfc_temp:units = "celsius" ;
data:

 sfc_temp =
  10, 10.1,
  10.2, 10.3,
  10.4, 10.5 ;
}

\end{verbatim}
}
\end{varwidth}
%\caption{C++ code}
\end{figure}

\item The NetCDF system includes utilities for producing human-oriented CDL text files from binary NetCDF datasets and vice-versa.

\end{itemize}

\nocite{netcdf}

\end{frame}

\subsection{NetCDF Data Models}

\begin{frame}[fragile]{The Classic NetCDF Model}

\begin{itemize}

\item A NetCDF file (dataset) has a path name and possibly some dimensions, variables, global (file-level) attributes, and data values associated with the variables.

\end{itemize}

\begin{center}
\includegraphics[scale=0.6]{fig/netcdf-classic}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{NetCDF Data Models}

    \begin{itemize}

        \item Classic: Simplest model -- Dimensions, variables, attributes

        \item {\color{red}{Enhanced: More powerful model -- Adds groups, types, nesting}}

    \end{itemize}

    \begin{center}
    \includegraphics[scale=0.45]{fig/nc4-uml}
    \end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The NetCDF-4 Enhanced Data Model}

\begin{itemize}
\setlength\itemsep{0.6cm}

    \item The NetCDF-4 Enhanced Data Model, which is known as the ``Common Data Model'', is part of an effort of Unidata to find a common engineering language for the development of scientific data solutions.

    \item The model contains the variables, dimensions, and attributes of the classic data model, but adds:

    \begin{itemize}

        \item Groups -- A way of hierarchically organizing data, similar to directories in a Unix file system.\\[0.2cm]

        \item User-defined types -- The user can now define compound types (like C structures), enumeration types, variable length arrays, and opaque types.

    \end{itemize}

\end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The NetCDF-4 Enhanced Data Model}

    \begin{itemize}
    \setlength\itemsep{0.5cm}
        \item A file has a top-level unnamed group.
        \item Each group may contain one or more named subgroups, user-defined types, variables, dimensions, and attributes.
        \item Variables also have attributes.
        \item Variables may share dimensions, indicating a common grid.
        \item One or more dimensions may be of unlimited length.
    \end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{NetCDF Library Architecture}

\begin{center}
\begin{tabular}{ccc}
\includegraphics[scale=0.3]{fig/netcdf-architecture}
& $\qquad$ &
\raisebox{3cm}{\includegraphics[scale=0.5]{fig/netcdf-architecture2}}
\end{tabular}
\end{center}

\end{frame}

\subsection{Best Practices for Writing NetCDF Files}

\begin{frame}[fragile]{Experience-based ``Best Practices'' for Writing NetCDF Files}

    \begin{itemize}
    \setlength\itemsep{0.4cm}

        \item	Conventions
        \begin{itemize}
          \item Developers should be familiar with and use existing NetCDF conventions.
        \end{itemize}

        \item	Coordinate Systems
        \begin{itemize}
          \item Spatial and temporal location of data are supported by use of coordinate systems.
        \end{itemize}

        \item	Variable Grouping
        \begin{itemize}
          \item How you group data into variables can determine whether common analysis and visualization software can effectively use the data.
        \end{itemize}

        \item	Variable Attributes
        \begin{itemize}
          \item Conventional variable attributes supply necessary metadata.
        \end{itemize}

    \end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{Experience-based ``Best Practices'' for Writing NetCDF Files}

    \begin{itemize}
    \setlength\itemsep{0.5cm}

        \item	Strings and Character Variables
        \begin{itemize}
          \item Use character data properly for representing text strings.
        \end{itemize}

        \item Calendar Date and Time
        \begin{itemize}
          \item Represent calendar dates and times with standards and conventions.
        \end{itemize}

        \item	Packed Data Values
        \begin{itemize}
          \item Conventions for packing numeric data to save space have some subtleties.
        \end{itemize}

        \item Missing Data Values
        \begin{itemize}
          \item To indicate that data values are missing, invalid, or not written, special values are conventionally used.
        \end{itemize}

    \end{itemize}

\nocite{netcdf}

\end{frame}

\subsection{Climate and Forecast (CF) Conventions}

\begin{frame}[fragile]{Climate and Forecast (CF) Conventions}

\begin{itemize}
\setlength\itemsep{0.3cm}

\item The Climate and Forecast (CF) conventions are metadata conventions for earth science data, intended to promote the processing and sharing of files created with the NetCDF API.

% \item The CF conventions define metadata that are included in the same file as the data (thus making the file ``self-describing'').

\item The purpose of the CF conventions is to require conforming datasets to contain sufficient metadata that they are self-describing:

    \begin{itemize}

      \item Each variable in the file has an associated description of what it represents, including physical units if appropriate.

      \item Each value can be located in space (relative to earth-based coordinates) and time.

    \end{itemize}

\item The CF conventions enable users of data from different sources to decide which data are comparable and allows building applications with powerful extraction, regridding, and display capabilities.

\end{itemize}

\end{frame}

\section{Parallel I/O}
\sectionIntro
\label{sec:pio}

\begin{frame}[fragile]{Parallel I/O}

\begin{itemize}
\setlength\itemsep{0.1cm}

  \item Parallel I/O allows each processor in a multi-processor system to read and write data from multiple processes to a common file independently.

  \begin{center}
  \includegraphics[scale=0.5]{fig/pnetcdf}
  \end{center}

  \item Data-intensive scientific applications use parallel I/O software to access files.

  \item In HPC, increasing demands in the I/O system can cause bottlenecks. Parallel I/O plays a fundamental role to balance the fast increase in computational power and the progress of processor architectures.

  \item Used properly, parallel I/O allows users to overcome I/O bottlenecks in HPC environments.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Parallel I/O in NetCDF-4}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item NetCDF-4 provides parallel file access to both classic and NetCDF-4/HDF5 files.

  \item The parallel I/O to NetCDF-4 files is achieved through the HDF5 library while the parallel I/O to classic files is through PNetCDF.

  \item NetCDF-4 exposes the parallel I/O features of HDF5.
    \begin{itemize}
    \item HDF5 provides easy-to-use parallel I/O feature.
    \end{itemize}

  \item Parallel NetCDF uses MPI I/O to perform parallel I/O. It is a complete rewrite of the core C library using MPI I/O instead of POSIX.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Using Parallel I/O in NetCDF-4}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Special \verb|nc_create_par| and \verb|nc_open_par| functions are used to create/open a NetCDF file.

  \item The files they open are normal NetCDF-4/HDF5 files, but these functions also take MPI parameters.

  \item The parallel access associated with these functions is not a characteristic of the data file, but the way it was opened. The data file is the same, but using the parallel \verb|open/create| function allows parallel I/O to take place.

\end{itemize}

\begin{figure}
\centering
\begin{varwidth}{\linewidth}
{ \tiny

\begin{verbatim}

EXTERNL int
nc_create_par(const char *path, int cmode, MPI_Comm comm,
               MPI_Info info, int *ncidp);

EXTERNL int
nc_open_par(const char *path, int mode, MPI_Comm comm,
             MPI_Info info, int *ncidp);

\end{verbatim}

}
\end{varwidth}
\end{figure}

\end{frame}

\begin{frame}[fragile]{Collective and Independent Operations with Parallel I/O}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item In MPI programs, I/O may be collective or independent.

    \begin{itemize}
      \item Collective: It must be done by all processes at the same time
      \item Independent: It can be done by any process at any time.
    \end{itemize}

  \item All NetCDF metadata writing operations are collective. That is, all creation of groups, types, variables, dimensions, or attributes.

  \item Data reads and writes (ex. calls to \verb|nc_put_vara_int| and \verb|nc_get_vara_int|) may be independent (the default) or collective. To make writes to a variable collective, call the \verb|nc_var_par_access| function.

\end{itemize}

\begin{figure}
\centering
\begin{varwidth}{\linewidth}
{ \tiny

\begin{verbatim}

/* Use these with nc_var_par_access(). */
#define NC_INDEPENDENT 0
#define NC_COLLECTIVE 1

EXTERNL int
nc_var_par_access(int ncid, int varid, int par_access);

\end{verbatim}

}
\end{varwidth}
\end{figure}

\end{frame}

\section{Research Activities}
\sectionIntro
\label{sec:res}

\subsection{WP4}

\begin{frame}[fragile]{ESiWACE -- Work Package 4}

\begin{columns}

\begin{column}{0.7\textwidth}

\begin{block}{Objectives}
\begin{itemize}
\setlength\itemsep{0.5cm}
  \item Support data reduction in ensembles by providing tools to carry out ensemble statistics ``in-flight'' and compress ensemble members.
  \item Hide complexity of multiple-storage tiers (middleware between NetCDF and storage) with industrial prototype backends.
  \item Deliver portable workflow support for manual migration of semantically important content between disk, tape, and object stores.
\end{itemize}
\end{block}

\end{column}

\begin{column}{0.3\textwidth}
\begin{center}
\raisebox{0.5cm}{\includegraphics[scale=0.5]{fig/wp4}}
\end{center}
\end{column}

\end{columns}

\end{frame}

\subsection{ESDM}

\begin{frame}[fragile]{Earth-System Data Middleware (ESDM)}

\begin{block}{A transitional approach towards a vision for I/O addressing}
\begin{itemize}
\setlength\itemsep{0.1cm}
  \item Scalable data management practice
  \item The inhomogeneous storage stack
  \item Suboptimal performance and performance portability
  \item Data conversion/merging
\end{itemize}
\end{block}

\begin{block}{Design goals of the Earth-System Data Middleware}
\begin{enumerate}
\setlength\itemsep{0.1cm}
  \item Relaxed access semantics, tailored to scientific data generation
  \item Site-specific (optimized) data layout schemes
  \item Ease of use and deploy a particular configuration
  \item Enable a configurable namespace based on scientific metadata
\end{enumerate}
\end{block}

\end{frame}

\begin{frame}[fragile]{ESDM -- Architecture}

\begin{block}{\textbf{Key Concept}: Decouple data localization decisions from science}
\begin{itemize}
\setlength\itemsep{0.2cm}
  \item Middleware utilizes layout component to make placement decisions
  \item Applications work through existing API
  \item Data is then written/read efficiently; potential for optimization inside library
\end{itemize}
\end{block}

\begin{center}
\includegraphics[scale=0.6]{fig/esdm-arch}
\end{center}

\end{frame}

\begin{frame}[fragile]{ESDM -- Benefits}

\begin{itemize}
\setlength\itemsep{0.4cm}
  \item Expose/access the same data via different APIs
  \item Independent and lock-free writes from parallel applications
  \item No fixed storage layout
  \item Less performance tuning from users needed
  \item Exploit characteristics of different storage technology
  \item Multiple layouts of one data structure optimize access patterns
  \item Flexible namespace (similar to MP3 library)
\end{itemize}

\end{frame}

\begin{frame}[fragile]{Next Generation Interfaces (NGI)}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item Towards a new I/O stack considering:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item User metadata and workflows as first-class citizens
    \item Smart hardware and software components
    \item Liquid-Computing: Smart-placement of computing
    \item Self-aware instead of unconscious
    \item Improving over time (self-learning, hardware upgrades)
  \end{itemize}

\item Why do we need a new domain-independent API?

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Other domains have similar issues
    \item It is a hard problem approached by countless approaches
    \item Harness RD\&E effort across domains
  \end{itemize}

\end{itemize}

\end{frame}

\subsection{Smart Compression}

\begin{frame}[fragile]{Smart Compression}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item The main purpose of compression methods is to shrink data and to save storage space.

\item Compression methods also possess a huge potential to reduce the gap between computational power and I/O performance.
\begin{itemize}
\item Often, after compression, less data has to be moved.
\end{itemize}

\item Many modern file formats, in particular HDF5 and NetCDF-4, provide native support for compression.
\begin{itemize}
\item Beneficial in climate science, where data amounts are huge and are growing constantly.
\end{itemize}

\item The compression algorithms used in HDF5 and NetCDF-4 are lossless and do not meet the requirements of climate science to full extent.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Scientific Compression Library (SCIL)}

\begin{itemize}
\setlength\itemsep{0.2cm}
    \item In ESiWACE, SCIL is integrated into ESDM to allow scientists to specify the data properties on datasets.

    \begin{itemize}
    \setlength\itemsep{0.2cm}
        \item Developed in the AIMES Project\footnote{Advanced Computation and I/O Methods for Earth-System Simulations (AIMES) Project.}.
        \item The main purpose of SCIL is compression/decompression of scientific data, especially, of climate modeling data.
        \item Uses different third party compression libraries as well as specifically developed lossy and lossless compression methods.
        \item Separates concern of data accuracy and choice of algorithms.
        \item Users specify necessary accuracy and performance parameters.
        \item Metacompression library makes the choice of algorithms.
        \item Supports new algorithms.
    \end{itemize}

\end{itemize}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Stack}

\begin{center}
\includegraphics[scale=0.7]{fig/stack3}
\end{center}

\end{frame}

\begin{frame}[fragile]{Previous Learning Objectives}

\begin{itemize}

    \item Describe the general layers involved in I/O on a supercomputer
    \item Analyse the implications of parallel I/O on application efficiency
    \item Identify typical I/O performance issues and their causes
    \item Design a data model for NetCDF/CF
    \item Read, analyse, and write NetCDF files in a metadata-aware manner
    \item Visualise and regrid field constructs within NetCDF

\end{itemize}

\end{frame}

\end{comment}

\begin{frame}[allowframebreaks]{Bibliography}

{

\tiny

\bibliographystyle{alpha}
\bibliography{io}

}

\end{frame}

\acknowledgement

\appendix

\begin{frame}[fragile]{}

{ \huge \color{EsiBlue}{ Appendix}}

\end{frame}

\section{ESDM Architecture}

\begin{frame}[fragile]{ESDM Architecture}

\begin{center}
\includegraphics[scale=0.35]{fig/esdm-arch1}
\end{center}

\end{frame}

\begin{frame}[fragile]{ESDM Architecture and Interactions}

\begin{center}
\includegraphics[scale=0.3]{fig/esdm-arch2}
\end{center}

\end{frame}

\end{document}
