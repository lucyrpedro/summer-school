\documentclass[compress,11pt,xcolor=svgnames,aspectratio=169]{beamer}
\usetheme{Esiwace}
\usefonttheme[onlysmall]{structurebold}

%\usepackage{caption}
%\captionsetup{labelformat=empty, format=plain, labelsep=none,textfont=footnotesize}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{eurosym}
%\usepackage{ulem}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{pgfgantt}
\usepackage{comment}
\usepackage{tikz}
% \usepackage[backend=bibtex]{biblatex}
% \bibliography{io} % \footfullcite{jones00}
% \usepackage[numbers]{natbib}
\usepackage[absolute,overlay]{textpos}
\usepackage{varwidth}
\usepackage{cancel}
\usepackage{ulem}

\newcommand{\lr}[1]{\textcolor{cyan}{LR: #1}}
\setbeamercolor{bibliography item}{parent=palette primary}

\newcommand{\sectionIntro}{
\begin{frame}{Outline}
  \begin{centering}
  {\scriptsize
  \tableofcontents[currentsection,hideothersubsections]%,subsectionstyle=hide/hide/hide
  }
  \end{centering}
\end{frame}
}

\newcommand{\sectionIntroHidden}{
\begin{frame}{Outline}
  \begin{centering}
  {\scriptsize
  \tableofcontents[currentsection,subsectionstyle=hide/hide/hide]
  }
  \end{centering}
\end{frame}
}

\definecolor{gold}{rgb}{0.83, 0.69, 0.22}

\makeatletter
\renewcommand{\itemize}[1][]{%
  \beamer@ifempty{#1}{}{\def\beamer@defaultospec{#1}}%
  \ifnum \@itemdepth >2\relax\@toodeep\else
    \advance\@itemdepth\@ne
    \beamer@computepref\@itemdepth% sets \beameritemnestingprefix
    \usebeamerfont{itemize/enumerate \beameritemnestingprefix body}%
    \usebeamercolor[fg]{itemize/enumerate \beameritemnestingprefix body}%
    \usebeamertemplate{itemize/enumerate \beameritemnestingprefix body begin}%
    \list
      {\usebeamertemplate{itemize \beameritemnestingprefix item}}
      {\def\makelabel##1{%
          {%
            \hss\llap{{%
                \usebeamerfont*{itemize \beameritemnestingprefix item}%
                \usebeamercolor[fg]{itemize \beameritemnestingprefix item}##1}}%
          }%
        }%
      }
  \fi%
  \beamer@cramped%
  \justifying% NEW
  %\raggedright% ORIGINAL
  \beamer@firstlineitemizeunskip%
}
\makeatother

\tcbuselibrary{raster}

\DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg}
\graphicspath{{./fig/}}

\title[Input/Output and Middleware -- Talk Session]{2020 Summer School on Effective HPC for Climate and Weather \\[0.5cm] Input/Output and Middleware}
\author[Pedro, Kunkel]{Luciana Pedro, Julian Kunkel
}
\institute[WP4 Team]{Department of Computer Science, University of Reading}
\date{25 August 2020}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[plain]
    \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{withoutheadline}
\begin{frame}{Outline}
    \begin{centering}
    {\tiny
    \tableofcontents[hideallsubsections]
    }
    \end{centering}
    \disclaimer
\end{frame}
\end{withoutheadline}

% Input/Output and Middleware
% Climate and weather research is typically data-intensive and applications must utilise input/output efficiently. Often, a user struggles to assess observed performance leading to superflux attempts to tune the application and optimise performance in a wrong layer of the stack. The content of this session is twofold. Firstly, we discuss storage layers focusing on the NetCDF middleware and provide a performance model that aids users to identify inefficient I/O. Secondly, we introduce the NetCDF Climate and Forecast (CF) conventions that are often used as a standard to exchange data.

\begin{frame}[fragile]{Learning Objectives -- Talk}

{\footnotesize

\begin{itemize}
\setlength\itemsep{0.4cm}
  \item Discuss challenges for data-driven research (Section \nameref{sec:intro})
  \item Describe the role of middleware and file formats (Section \nameref{sec:io-sol})
  \item Identify typical I/O performance issues and their causes (Section \nameref{sec:io-sol})
  \item Apply performance models to assess and optimise the application I/O performance (Section \nameref{sec:io-perf})
  \item Design a data model for NetCDF/CF (Section \nameref{sec:netcdf})
  \item Implement an application that utilises parallel I/O to store and analyse data (Section \nameref{sec:pio})
  \item Describe ongoing research activities in high-performance storage (Section \nameref{sec:res})
\end{itemize}

}

\end{frame}

\begin{frame}[fragile]{Learning Objectives -- Lab}

{\footnotesize

\begin{itemize}
\setlength\itemsep{1cm}
  \item Execute programs in C that read and write NetCDF files in a metadata-aware manner
  \item Analyse, manipulate and visualise NetCDF data
  \item Implement an application that utilises parallel I/O to store and analyse data
\end{itemize}

}

\end{frame}

\section{Introduction}
\sectionIntro
\label{sec:intro}

\subsection{I/O Bottleneck}

\begin{frame}[fragile]{I/O Bottleneck -- Titan}

\begin{center}
\includegraphics[scale=0.45]{fig/bottleneck}
\end{center}

\nocite{sensei-sc17}

\end{frame}

\begin{frame}[fragile]{I/O Bottleneck -- Mistral}

\begin{itemize}
\setlength\itemsep{0.4cm}
\item Predict processor performance growth by 20x each generation ($\sim$5 years).
\item Storage throughput/capacity improves by just 6x.
\item Costs and performance come together.
\end{itemize}

\vspace*{-1.6cm}

\begin{center}
\begin{tabular}{cc}
& { \footnotesize Real Values -- 2018} \\
\raisebox{1cm}{\includegraphics[scale=0.4]{fig/bottleneck-dkrz}} &
\raisebox{0.6cm}{\includegraphics[scale=0.45]{fig/mistral}}
\end{tabular}
\end{center}

\nocite{ESSAASOEKK14}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.7]{fig/FoldersVsMeta}
\end{center}

\end{frame}

\subsection{Data-driven Research}

\begin{frame}[fragile]{Data-driven Research}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item \textbf{Data-driven Research} is the science of letting data tell us what we are looking for.
    \begin{itemize}
      \item \textbf{Database Management} is the science of efficiently storing and retrieving data.
      \item \textbf{Data Mining} is the science of discovering hidden correlations in data.
    \end{itemize}

  \item In HPC, the concerns of \textbf{storage} and \textbf{computing} are traditionally separated and optimised independently from each other and the needs of the end-to-end user.

  \item Workflows composed of data, computing, and communication-intensive tasks should drive interfaces and hardware configurations to best support the programming models.

  \item Data-driven workflows may benefit from the explicit and simultaneous use of a locally heterogeneous set of computing and storage technologies.

%  \item Many processes still require experts. For example, porting a workflow from one system to another still requires adjusting runtime parameters of applications and deciding on how data is managed.

\end{itemize}

\nocite{01403233}

\nocite{JSFI309}

\end{frame}

\section{Input/Output}
\sectionIntro
\label{sec:io}

\begin{frame}[fragile]{Input/Output}

\begin{itemize}
\setlength\itemsep{0.3cm}

    \item Input/Output (I/O) is simply data migration.

    \begin{itemize}
      \item Memory $\Leftrightarrow$ Disk
    \end{itemize}

    \item I/O is a very expensive operation!

%    \begin{itemize}
%      \item Interactions with data in memory and on disk.
%    \end{itemize}

    \item How is I/O performed?

    \begin{itemize}

      \item I/O Pattern

      \begin{itemize}
        \item Number of processes and files.
        \item Characteristics of file access.
      \end{itemize}

    \end{itemize}

    \item Where is I/O performed?

    \begin{itemize}
      \item Characteristics of the computational system.
      \item Characteristics of the file system.
    \end{itemize}

\end{itemize}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Performance}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item There is no ``One Size Fits All'' solution to the I/O problem.

  \item Bottlenecks in performance can occur in many locations.

  \begin{itemize}
    \item Application and/or file system.
  \end{itemize}

  \item Many I/O patterns work well for some range of parameters.

  \item Going to extremes with an I/O pattern will typically lead to problems.

  \item {\color{gold}\textbf{Golden Rule:}} Increase performance by decreasing the number of I/O operations and increasing the size of each operation.

\end{itemize}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Types}

\begin{center}
\includegraphics[scale=0.35]{io-types}
\end{center}

\end{frame}

\begin{frame}[fragile]{I/O Access Patterns}

\begin{center}
\includegraphics[scale=0.35]{io-patterns}
\end{center}

\end{frame}

\begin{frame}[fragile]{File Striping}

\vspace*{-0.7cm}

\begin{center}
\includegraphics[scale=0.35]{fig/file-striping}
\end{center}

\nocite{PIOTAPO12}

\end{frame}

\begin{frame}[fragile]{I/O Stack}

{\tiny

\begin{columns}
\begin{column}{0.38\textwidth}
\begin{block}{Application}
\begin{itemize}
\item Weather forecasts.
\item Climate simulations, impacts, predictions and projections.
\item Decisions on emission reductions.
\item Strategies for housing, cities, farming, coastal defenses and other parts of society.
\end{itemize}
\end{block}
\begin{block}{High Level I/O Library}
\begin{itemize}
\item Match storage abstraction to domain.
\item Provide self-describing, structured files.
\item Map to middleware interface.
\item Implement further optimisations.
\end{itemize}
\end{block}
\end{column}
\begin{column}{0.24\textwidth}
\begin{center}
\includegraphics[scale=0.8]{fig/io-stack}
\end{center}
\end{column}
\begin{column}{0.38\textwidth}
\begin{block}{I/O Middleware}
\begin{itemize}
\item Match the programming model (e.g. MPI).
\item Facilitate concurrent access by groups of processes.
\item Expose a generic interface.
\item Efficiently map middleware operations into operations in the Parallel File System.
\end{itemize}
\end{block}
\begin{block}{Parallel File System}
\begin{itemize}
\item Manage storage hardware.
\item In the I/O software stack, focus on concurrent, independent access.
\item Publish an interface that middleware can use effectively.
\end{itemize}
\end{block}
\end{column}
\end{columns}

}

\nocite{esiwace}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Stack -- \lr{Alternative Slide}}

\begin{center}
\includegraphics[scale=0.7]{fig/stack2}
\end{center}

\end{frame}

\end{comment}

\begin{frame}[fragile]{I/O Problems}

\begin{itemize}
\setlength\itemsep{0.7cm}

\item Not enough I/O capacity on current HPC systems, and the trend is getting worse.

\item If there is not enough I/O, you cannot write data and then you can not analyse it.
    \begin{itemize}
        \item Lost science!
    \end{itemize}

\item Missing opportunity of doing better science (analysis) when have access to full spatiotemporal resolution data.

\item Energy consumption: it costs a lot of power to write data to disk.

\end{itemize}

\nocite{sensei-sc17}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{Challenges in Domain of Climate and Weather}

\begin{itemize}
\setlength\itemsep{0.2cm}

\item High data volume and velocity

\item Data management practice does not scale

  \begin{itemize}
      \item E.g., hierarchical namespaces does not reflect use cases
      \item Scientists spend quite some time to define the namespace
  \end{itemize}

\item Suboptimal performance (and performance portability) of data formats

  \begin{itemize}
    \item Tuning for NetCDF, HDF5 and GRIB necessary
    \item Scientists worry about interoperability
  \end{itemize}

\item Data conversion is often needed

  \begin{itemize}
    \item Between formats such as NetCDF and GRIB
    \item To combine data from multiple experiments, time steps, etc.
  \end{itemize}

\item External data services to share data in the community

  \begin{itemize}
    \item (Scientific) metadata is provided by databases
  \end{itemize}

\end{itemize}

\end{frame}

\end{comment}

\section{I/O Solutions}
\sectionIntro
\label{sec:io-sol}

\begin{frame}[fragile]{I/O Solutions}

\begin{itemize}

\item As we are moving towards exascale, the gap between computing power and I/O bandwidth will
widen and researchers are looking for solutions to tackle this problem.\\[0.4cm]

\item There are essentially three lines of research:\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

      \item at hardware level,
      \item at middleware level,
      \item and at application level.

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\subsection{Hardware Level}

\begin{frame}[fragile]{Hardware Level}

\begin{itemize}

    \item Non-volatile memory (NVM)\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

        \item Non-volatile memory (NVM) is a type of computer memory that can retrieve stored information even after having been power cycled.

        \item The capabilities of NVM (i.e., capacity, bandwidth, energy consumption) are somewhere in-between main memory and persistent storage, thus it is often used as a ``caching'' solution between these two layers.

        \item Examples of non-volatile memory include read-only memory (ROM), non-volatile random-access memory (NVRAM), magnetic (tape data storage and hard disk), and optical (disc and 5D optical data storage).

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Hardware Level}

\begin{itemize}

    \item Burst buffer (BB)\\[0.4cm]

      \begin{itemize}
      \setlength\itemsep{0.5cm}

      \item Burst buffer (BB) is a fast and intermediate storage layer positioned between the front-end computing processes and the backend storage systems.

      \item HPC applications often show bursty I/O behavior (i.e., all processes read/write at the same time) and burst buffers help to absorb these workloads.

      \item Burst buffer is built from arrays of high-performance storage devices, such as NVRAM and SSD.

      \end{itemize}

\begin{comment}

      \begin{center}
      \begin{tabular}{ccccc}
      \raisebox{1cm}{NVRAM} &
      \includegraphics[scale=0.25]{fig/nvram} & $\qquad$ &
      \includegraphics[scale=0.24]{fig/ssd} &
      \raisebox{1cm}{
        \begin{tabular}{c}
        SSD \\
        (on top of \\
        a hard drive)
        \end{tabular}
      }
      \end{tabular}
      \end{center}

\end{comment}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{Hardware Level \lr{(Keep it?)}}

\begin{itemize}

      \item Multi-layer Storage Hierarchy (Examples)\\[0.4cm]

        \begin{itemize}
        \setlength\itemsep{0.6cm}

        \item Attached SSDs to compute nodes to aggregate many small I/O requests into few larger ones and/or to compute nodes to speed-up MPI-I/O.

        \item Multi-layer storage hierarchy with NVM, SSDs, and different types of hard disks. % drives.

        \item Fast Forward Storage and IO (FFSIO), SAGE, Distributed Application Object Store (DAOS), Post-Petascale File System (PPFS), Scalable Object-Centric Metadata Management (SoMeta), Extensible Metadata Provider for Extreme-Scale Scientific Simulations (EMPRESS), TÃ½r

        \item ECP [16], Fast-Forward [44], ADIOS [72], HDF VOL [29], ESiWACE [20], NEXTGenIO [69] and SAGE [78]

        \item Blue gene active storage, Dash

        \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Middleware -- Definition}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item Middleware is software occupying a middle position between application programs and operating systems.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/middleware2}
\end{center}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Middleware}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item Middleware is in the middle of the vertical stack, between the application programs and the operating system.

  \item Viewed horizontally rather than vertically, middleware is also in the middle of interactions between different application programs (possibly even running on different computer systems), because it provides mechanisms to support controlled interaction through coordination, persistent storage, naming, and communication.

  \item Middleware provide a more sophisticated form of persistent storage than the standard supported by most operating systems.

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Middleware -- Examples}

\begin{itemize}
\setlength\itemsep{0.6cm}

\item Common middleware examples include relational database systems, application server middleware, message-oriented middleware, web middleware, and transaction-processing monitors.

  \begin{itemize}
  \setlength\itemsep{0.4cm}

  \item Relational Database Management Systems (RDBMS): Oracle Database\footnote{\tiny \url{https://www.oracle.com/database/technologies/}} and PostgreSQL\footnote{\tiny \url{https://www.postgresql.org/}}.

  \item Messaging Systems: IBM MQ\footnote{\tiny \url{https://www.ibm.com/uk-en/products/mq}}, Jakarta Messaging API\footnote{\tiny \url{https://projects.eclipse.org/projects/ee4j.jms}}, and Java RMI (Remote Method Invocation)\footnote{\tiny \url{https://www.oracle.com/java/technologies/javase/remote-method-invocation-home.html}}.

  \item \lr{Input/Output Systems: ESDM}

  \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item Operating systems and middleware have much in common.

  \item Both are software used to support other software, such as the application programs you run.

  \item Both provide a similar range of services centered around \textit{controlled interaction}.

  \item \textbf{Controlled Interaction} is the interaction between concurrent computations.\\[0.3cm]

  \begin{itemize}
  \setlength\itemsep{0.4cm}
    \item On the same system -- As between your email program and your word processor.
    \item Across time -- As between your word processor before your trip and your word processor after your trip.
    \item Across space -- As between your email program and your service provider's email server.
  \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item Like an operating system, middleware may enforce rules designed to keep the computations from interfering with one another. An example is the rule that only one computation may modify a shared data structure at a time.

  \item Like an operating system, middleware may bring computations at different times into contact through persistent storage and may support interaction between computations on different computers by providing network communication services.

  \item However, operating systems and middleware are not the same.

  \item They rely upon different underlying providers of lower-level services.

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Operating Systems and Middleware}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item An operating system provides the services in its API by making use of the features supported by the hardware.

    \begin{itemize}
    \setlength\itemsep{0.4cm}
        \item For example, it might provide API services of reading and writing \lr{named} \lr{Named Binary Tag (NBT)?}, variable-length files by making use of a disk drive's ability to read and write \lr{numbered} \lr{???}, fixed-length blocks of data.
    \end{itemize}

  \item Middleware, on the other hand, provides the services in its API by making use of the features supported by an underlying operating system.

    \begin{itemize}
    \setlength\itemsep{0.4cm}
        \item For example, the middleware might provide API services for updating relational database tables by making use of an operating system's ability to read and write files that contain the database.
        \item \lr{ESDM!}
    \end{itemize}

\end{itemize}

\nocite{hailperin2006operating}

\end{frame}

\begin{frame}[fragile]{Describe the role of middleware and file formats}

\begin{itemize}

  \item File formats
    \begin{itemize}
        \item
        \item
    \end{itemize}

  \item
    \begin{itemize}
      \item
    \end{itemize}

\end{itemize}

\end{frame}

\end{comment}

\subsection{Middleware Level}

\begin{frame}[fragile]{Middleware Level}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item Solutions in I/O middleware.

    \begin{itemize}

    \item E.g., file systems, I/O interfaces.

    \end{itemize}

\item \textbf{Damaris:} Software framework that overlaps computation and I/O operations by dedicating a single core to I/O tasks.

\item \textbf{ADIOS:} I/O abstraction framework for HPC applications that enables switching between different I/O transport methods with little modification to application code and enabling integration of new I/O solutions.

\item \textbf{DeltaFS:} File systems that improves the scalability of file systems by letting compute nodes manage metadata instead of a centralised server.

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Ongoing Activity: Earth-System Data Middleware}

\begin{itemize}
\setlength\itemsep{0.4cm}

    \item ESDM provides a transitional approach towards a vision for I/O addressing\\[0.3cm]

    \begin{itemize}
    \setlength\itemsep{0.4cm}
    \item Scalable data management practice
    \item The inhomogeneous storage stack
    \item Suboptimal performance and performance portability
    \item Data conversion/merging

    \end{itemize}

    \item Part of the ESiWACE Project\footnote{Centre of Excellence in Simulation of Weather and Climate in Europe.}

\end{itemize}

\end{frame}

\subsection{Application Level}

\begin{frame}[fragile]{Application Level}

\begin{itemize}

\item In-situ analysis\\[0.4cm]

    \begin{itemize}
    \setlength\itemsep{0.6cm}

    \item In biology and biomedical engineering, in situ means to examine the phenomenon exactly in place where it occurs (i.e., without moving it to some special medium).

    \item Rather than applications writing their raw output to storage to later be read again for post-processing (e.g., visualisation, filtering, statistics), in-situ processing removes this overhead by performing the analysis directly on the same machines as where the applications run.

    \item ParaView, Dax, and Damaris/Viz are tools for large-scale in-situ visualisation.

    \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\begin{frame}[fragile]{Discussion}

\begin{itemize}
\setlength\itemsep{0.2cm}

\item No ``One Size Fits All'' solution to the storage problem and programmers must take I/O into careful consideration when developing applications.

\item Mismatch between the massive computational performance of processors and relatively limited I/O bandwidth of storage systems.

\item Three methods to alleviate this problem: new hardware technology, new I/O middleware, and application-specific solutions.

  \begin{itemize}
  \setlength\itemsep{0.2cm}

  \item Hardware technology shows promising solutions, but different systems might employ different solutions, reducing the portability and increasing the complexity. % of software.

  \item Middleware can alleviate some of this complexity with solutions such as ADIOS and ESDM.

  \item In-situ analysis is an example of how application-specific solutions can be used to improve I/O throughput and thus application performance.

  \end{itemize}

\end{itemize}

\nocite{3372390}

\end{frame}

\section{I/O Performance}
\sectionIntro
\label{sec:io-perf}

\begin{frame}[fragile]{I/O Performance}

\begin{itemize}
\setlength\itemsep{0.8cm}

  \item There are several aspects involved in delivering high I/O performance to parallel applications, from hardware characteristics to methods that manipulate workloads to improve achievable performance.

  \item Running the same application with different I/O configurations gives the possibility to tune the I/O system according to the application access pattern.

  \item Another way to predict application performance in HPC systems with different I/O configurations is by using modeling and simulation techniques.

\end{itemize}

\nocite{SOPPOAASLK13}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.5]{fig/tree-perf}
\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\subsection{I/O Performance Factors}

\begin{frame}[fragile]{I/O Performance Factor -- Access Patterns}

\vspace*{0.6cm}

\begin{itemize}
\setlength\itemsep{1cm}

  \item The access pattern describes how\\ spatial access is performed over time.

  \item With an access pattern, the I/O of a single client process can be described, but also the actual observable patterns on the I/O servers, or on a single block device.

  \item The pattern on the I/O servers is caused by all clients and defines the performance of the I/O subsystems.

\end{itemize}

%\begin{textblock}{20}(40,20)
\begin{textblock}{2}(9,3)
   \includegraphics[scale=0.5]{fig/tree-io-ac-pat}
\end{textblock}

%\begin{picture}(50,50)
%\put(10,10){\hbox{\includegraphics[scale=0.3]{fig/tree-io-ac-pat}}}
%\put(200,-300){\hbox{\includegraphics[scale=0.3]{fig/tree-io-ac-pat}}}
%\end{picture}

%\begin{center}
%\includegraphics[scale=0.6]{fig/tree-io-ac-pat}
%\end{center}

\nocite{pio-sc17}

\end{frame}

\begin{frame}[fragile]{I/O Performance Factor -- I/O Strategy}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item In general, the mechanisms introduced here are orthogonal to the hardware and the architecture of the parallel file system.

  \item On the client-side, for instance, \\
  requests could already be tuned to improve \\
  the access pattern which will be observed \\
  on the servers.

  \item Similar to optimisations in communication, \\
  these strategies could be applied on any layer involved in I/O.

\end{itemize}

\begin{textblock}{0}(9,5)
   \includegraphics[scale=0.4]{fig/tree-io-strat}
\end{textblock}

%\begin{center}
%\includegraphics[scale=0.6]{fig/tree-io-strat}
%\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\begin{frame}[fragile]{I/O Performance Factor -- Parallel File System}

\begin{itemize}
\setlength\itemsep{0.5cm}

  \item Performance of a parallel file system highly depends on its design as it provides the frame for the deployed optimisation strategies.

  \item Several aspects like consistency semantics also apply to higher level interfaces like domain specific I/O libraries.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/tree-io-pfs}
\end{center}

\nocite{SOPPOAASLK13}

\end{frame}

\subsection{I/O Performance Analysis}

\begin{frame}[fragile]{I/O Performance Analysis}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Problem

    \begin{itemize}
    \item Assessing observed time for I/O is difficult.
    \item What best-case performance can we expect?
    \end{itemize}

  \item Support for performance analysis
  \setlength\itemsep{0.4cm}

    \begin{itemize}

    \item Models and simulation

      \begin{itemize}
        \item Trivial models -- Using throughput and latency
      \end{itemize}

    \item Tools to capture and analyse system statistics and I/O activities

      \begin{itemize}
        \item Darshan -- Tool to identify I/O patterns and assess the performance
        \item Grafana -- Online monitoring
      \end{itemize}

    \item Benchmarks -- On various levels, e.g., Metadata (md-workbench, IOR)

    \end{itemize}

\end{itemize}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{Big Data Cluster Characteristics}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Usually commodity components
  \item Cheap (on-board) interconnect, node-local storage
  \item Communication (bisection) bandwidth between different racks is low

\end{itemize}

\begin{center}
\includegraphics[scale=0.45]{fig/arch1}
\end{center}

\end{frame}

\end{comment}

\begin{frame}[fragile]{HPC Cluster Characteristics}

\begin{columns}

\begin{column}{0.32\textwidth}

\begin{itemize}
\setlength\itemsep{0.6cm}
  \item High-end components
  \item Extra fast interconnect, global/shared storage with dedicated servers
  \item Network provides high (near-full) bisection bandwidth.
\end{itemize}

\end{column}

\begin{column}{0.6\textwidth}
\begin{center}
\raisebox{0.1cm}{\includegraphics[scale=0.55]{fig/arch2}}
\end{center}
\end{column}

\end{columns}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{Performance: Hierarchical Model \lr{Extra slide}}

\begin{center}
\includegraphics[scale=0.6]{fig/bottleneck3}
\end{center}

\end{frame}

\begin{frame}[fragile]{Hardware Performance}

\begin{block}{Computation}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item CPU performance (frequency $\times$ cores $\times$ sockets)

    \begin{itemize}
    \item E.g.: 2.5 GHz $\times$ 12 cores $\times$ 2 sockets = 60 Gcycles/s
    \item The number of cycles per operation depend on the instruction stream
    \end{itemize}

  \item Memory (throughput $\times$ channels)

    \begin{itemize}
    \item E.g.: 25.6 GB/s per DDR4 DIMM $\times$ 3
    \end{itemize}

\end{itemize}

\end{block}

\begin{block}{Communication via the network}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Throughput, e.g., 125 MiB/s with Gigabit Ethernet
  \item Latency, e.g., 0.1 ms with Gigabit Ethernet

\end{itemize}

\end{block}

\end{frame}

\end{comment}

\begin{frame}[fragile]{I/O Performance Analysis -- A Simple Model}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Communication between different machines is limited by the network performance.

  \item \textbf{Network throughput} is the amount of data moved successfully from one place to another in a given time period. The maximum throughput depends on the number of storage servers, client nodes and their network connectivity.

  \item Users typically know:

    \begin{itemize}
%    \setlength\itemsep{0.1cm}
      \item Output/input file size.
      \item Number of nodes a job run on.
      \item Runtime of the I/O during a job (this can be obtained with simple means).
    \end{itemize}

  \item Now compute the observed throughput (\verb|tp_obs|) in MiB/s per node. If \verb|tp_obs| is much smaller than the network throughput, then there might be an I/O problem.

  \item This is a very basic model that every user should understand and apply.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Analysis -- Numeric Example}

\begin{itemize}
%\setlength\itemsep{0.4cm}
\setlength\itemsep{0.2cm}

  \item Consider the following scenario:

    \begin{itemize}
    \setlength\itemsep{0.1cm}
      \item File size: 10 GiB
      \item Number of nodes: 10
      \item Time to transfer the data: 10 seconds
    \end{itemize}

  \item Calculating the throughput in this example, one will find:\\[0.2cm]

    \begin{itemize}
    \setlength\itemsep{0.2cm}
      \item $\displaystyle \frac{10\ \text{GiB}}{10\ \text{nodes} \times 10\ \text{seconds}} = 0.1\ \text{GiB/s per node} = 100\ \text{MiB/s per node}$.
    \end{itemize}

  \item Considering that a Gigabit Ethernet network should be capable of delivering a theoretical maximum transfer of about 125 MiB/s, the estimate throughput is close to the optimal value.

  \item However, if you are using an Infiniband capable of delivering 6 GiB/s, then 0.1 GiB/s is a problem.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Analysis -- Latency}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item \textbf{Network latency:} Time between the sending of a message and its arrival at the receiver side.

  \item \textbf{Network bandwidth:} Number of bits which can be transferred in a specific time.

  \item Because protocols like TCP have some overhead and control algorithms, the throughput is smaller than the bandwidth.

  \item Latency and bandwidth depend on the used network technology and topology.

  \item Say, for instance, you also know the number of I/O calls as well. Then, you can compute the latency per call.

    \begin{itemize}
    \setlength\itemsep{0.3cm}
      \item This information can actually be measured using Darshan, for example.
    \end{itemize}

  \item Now compute the calls per second per node and relate it to the network latency.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Improving I/O Performance}

\begin{itemize}
\setlength\itemsep{0.3cm}

\item Software and hardware tries to hide I/O penalty.

\item Caching of data:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Allow application to continue while I/O completes in the background (write-behind).
    \item Allow to aggregate multiple (small) operations into larger operations.
    \item Read data from disk before it is needed (read-ahead).
    \item \textbf{Require memory! Hiding vs. increased problem size!}
  \end{itemize}

\item Programming:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Overlap I/O (or communication) with computation.
    \item I/O and communication comes almost for free.
    \item Optimise file format and access pattern (more complicated).
  \end{itemize}

\end{itemize}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Performance Tuning ``Rules of Thumb''}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Use collective operations when possible

  \item Use high-level libraries (e.g. HDF5 or PNetCDF) when possible

  \item A few large I/O operations are better than many small I/O operations

  \item Avoid unnecessary metadata operations, especially \texttt{stat()}

  \item Avoid writing to shared files with POSIX

  \item Avoid leaving gaps/holes in files to be written later

  \item Use tools like \textbf{Darshan} to check assumptions about behavior

\end{itemize}

\end{frame}

\begin{frame}[fragile]{I/O Performance Model}

\nocite{CAPMFESDMA19}

\begin{center}
\includegraphics[scale=0.7]{fig/bottleneck3}
\end{center}

\end{frame}

\begin{frame}[fragile]{I/O Performance Model}

\nocite{CAPMFESDMA19}

\begin{center}
\includegraphics[scale=0.7]{fig/bottleneck4}
\end{center}

\end{frame}

\begin{frame}[fragile]{Assess and Optimise the Application I/O Performance}

\begin{itemize}
\setlength\itemsep{0.4cm}

    \item Develop general considerations about what influences the I/O performance

    \begin{itemize}
      \item What?
    \end{itemize}

    \item Analyse access pattern and define how it defines the performance of the I/O subsystems

    \begin{itemize}
      \item How?
    \end{itemize}

    \item Apply I/O strategies to improve the access pattern

    \begin{itemize}
      \item Which?
    \end{itemize}

    \item Identify options for the deployed optimisation strategies in a specific PVFS\footnote{Parallel Virtual File System.}

    \begin{itemize}
      \item Which?
    \end{itemize}

\end{itemize}

\nocite{SOPPOAASLK13}

\end{frame}

\end{comment}

\section{NetCDF}
\sectionIntro
\label{sec:netcdf}

\subsection{NetCDF Data Models}

\begin{frame}[fragile]{NetCDF}

\begin{itemize}
\setlength\itemsep{0.6cm}

\item In a simple view, NetCDF is:

    \begin{itemize}
        \item A data model.
        \item A file format.
        \item A set of APIs and libraries for various programming languages.
    \end{itemize}

\item Together, the data model, file format, and APIs support the creation, access, and sharing of scientific data.

\item NetCDF allows the user to describe multidimensional data and include metadata which further characterises the data.

\item NetCDF APIs are available for most programming languages used in geosciences.

\end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item NetCDF files are containers for Dimensions, Variables, and Global Attributes.

  \item A NetCDF file (dataset) has a path name and possibly some dimensions, variables, global (file-level) attributes, and data values associated with the variables.\\[0.4cm]

\end{itemize}

\begin{center}
\includegraphics[scale=0.6]{fig/netcdf-classic}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Dimensions}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Dimensions are used to specify variable shapes, grids, and coordinate systems.

  \item A dimension has a name and a length. Dimensions are used to define the shape of one or more variables in a NetCDF file.

  \item A dimension can be used to represent a real physical dimension, for example, time, latitude, longitude, or height.

  \item A dimension can also be used to index other quantities, for example, station or model run number. It is possible to use the same dimension more than once in specifying a variable shape.

\end{itemize}

\begin{center}
\includegraphics[scale=0.4]{fig/ncdim2}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Variables}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item Variables hold data values. In the classic NetCDF data model, a variable can hold a multidimensional array of values of the same type.

  \item A variable has a name, type, shape, attributes, and values.

  \item In the classic data model, the type of a variable is the external type of its data as represented on disk, one of: \texttt{char} (text character), \texttt{byte} (8 bits), \texttt{short} (16 bits), \texttt{int} (32 bits), \texttt{float} (32 bits), \texttt{double} (64 bits).

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/ncvar}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Variables}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item The shape of a variable is specified with a list of dimensions.

  \item A variable may have attributes to specify properties such as units.

  \item The values of variables are the data in a NetCDF file.

  \item A record variable is a variable that uses a record (or unlimited) dimension. It can grow efficiently by having data added along the record dimension.

  \item Things you can do with a NetCDF variable include getting information about it, putting data values into it, and getting data values out of it.

\end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Coordinate Variables}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item A one-dimensional variable with the same name as a dimension is a \textbf{coordinate variable}.

  \item The coordinate variable is associated with a dimension of one or more data variables and typically defines a physical coordinate corresponding to that dimension.

  \item Many programs that read NetCDF files recognise and use any coordinate values they find.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/nccoords}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Attributes}

\begin{itemize}
\setlength\itemsep{0.4cm}

  \item Attributes hold metadata (data about data). An attribute contains information about properties of a variable or dataset.

  \item An attribute has a name, type, and values. Attributes are used to specify such properties as units, standard names (that identify types of quantity), special values, maximum and minimum valid values, scaling factors, offsets, and measurement parameters.

\end{itemize}

\begin{center}
\includegraphics[scale=0.5]{fig/ncatts}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Attributes}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Things you can do with a NetCDF attribute include inquiring about its type or length, defining its value, and getting its value.
  \item Like variables, the type of an attribute may be one of char, byte, short, int, float, or double for the classic model.
  \item An attribute may have multiple values, but attributes cannot be multidimensional.
  \item Global attributes apply to a whole file. Variable attributes apply to a specific variable.
  \item NetCDF conventions are defined primarily in terms of attributes. Thus the names of attributes are standardised rather than the names of variables.
  \item Attributes cannot have attributes.
  \item Attributes are scalars or 1-D arrays.

\end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- UML Diagram}

\begin{itemize}

  \item The classic NetCDF data model uses dimensions, variables, and attributes, to capture the meaning of array-oriented scientific data.

\begin{comment}
  \item UML diagrams represent data models visually. Each box contains

  \begin{itemize}

    \item the name of a class of objects
    \item characteristics of object in the class
    \item operations (methods) for that class of objects

  \end{itemize}

  \item Connecting lines identify relationships of containment and use.
  \item Here is a simplified (we don't list all the methods) UML diagram of the classic NetCDF data model:
\end{comment}

\end{itemize}

\begin{center}
\includegraphics[scale=0.35]{fig/nc-classic-uml}
\end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The Classic NetCDF Model -- Data}

\begin{itemize}

  \item The data in a NetCDF file is stored in the form of arrays. For example:\\[0.2cm]

  \begin{itemize}
  \setlength\itemsep{0.2cm}

    \item Temperature varying over time at a location is stored as a \textbf{one-dimensional array}.
    \item Temperature over an area for a given time is stored as a \textbf{two-dimensional array}.
    \item Three-dimensional (3D) data, like temperature over an area varying with time, or four-dimensional (4D) data, like temperature over an area varying with time and altitude, is stored as a \textbf{series of two-dimensional arrays}.

  \end{itemize}

\end{itemize}

\begin{center}
\begin{tabular}{cc}
\includegraphics[scale=0.5]{fig/netcdf1} &
\includegraphics[scale=0.5]{fig/netcdf2}
\end{tabular}
\end{center}

{\tiny Reference: \url{https://pro.arcgis.com/en/pro-app/help/data/multidimensional/fundamentals-of-netcdf-data-storage.htm}}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{Common Data form Language (CDL)}

\vspace*{-0.5cm}

\begin{columns}

\begin{column}{0.5\textwidth}

{\footnotesize

  \begin{itemize}
  \setlength\itemsep{0.3cm}
    \item The notation used to describe a NetCDF object is called CDL (network Common Data form Language), which provides a convenient way of describing NetCDF datasets.
    \item The NetCDF system includes utilities for producing human-oriented CDL text files from binary NetCDF datasets and vice-versa.
    \item A NetCDF file contains dimensions, variables, and attributes.
    \item These components are used together to capture the meaning of data and relations among data fields in an array-oriented dataset.
  \end{itemize}
}

\end{column}

\begin{column}{0.4\textwidth}
\begin{center}
\includegraphics[scale=0.45]{fig/netcdf-cdl}
\end{center}
\end{column}

\end{columns}

\end{frame}

\begin{frame}[fragile]{NetCDF Data Models}

    \begin{itemize}

        \item Classic: Simplest model -- Dimensions, variables, attributes

        \item {\color{red}{Enhanced: More powerful model -- Adds groups, types, nesting}}

    \end{itemize}

    \begin{center}
    \includegraphics[scale=0.45]{fig/nc4-uml}
    \end{center}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The NetCDF-4 Enhanced Data Model}

\begin{itemize}
\setlength\itemsep{0.2cm}

    \item The NetCDF-4 Enhanced Data Model, which is known as the ``Common Data Model'', is part of an effort of Unidata to find a common engineering language for the development of scientific data solutions.

    \item The model contains the variables, dimensions, and attributes of the classic data model, but adds:\\[0.2cm]

    \begin{itemize}
    \setlength\itemsep{0.2cm}

        \item \textbf{Groups} -- A way of hierarchically organising data, similar to directories in a Unix file system.\\[0.2cm]

        \begin{itemize}
        \setlength\itemsep{0.1cm}
            \item A file has a top-level unnamed group.
            \item Each group may contain one or more named subgroups, user-defined types, variables, dimensions, and attributes.
        \end{itemize}

        \item \textbf{User-defined types} -- The user can now define compound types (like C structures), enumeration types, variable length arrays, and opaque types.

        \item One or more dimensions may be of \textbf{unlimited} length.

    \end{itemize}

\end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{The NetCDF-4 Enhanced Data Model -- CDL Files}

\begin{columns}

\begin{column}{0.35\textwidth}
\begin{block}{Groups}
\vspace*{-0.4cm}
{ \tiny
\begin{verbatim}
netcdf regions {
group: UK {
  dimensions:
    time = UNLIMITED ; // (2 currently)
  variables:
    float average_temperature(time) ;
  data:
   average_temperature = 13.4167, 63.4167 ;
  group: Reading {
    dimensions:
      stations = 5 ;
    variables:
      float temperature(time, stations) ;
    data:
     temperature =
       11, 12, 13, 14, 15,
       61, 62, 63, 64, 65 ;
    } // group Reading
  } // group UK
}
\end{verbatim}
}
\vspace*{-0.4cm}
\end{block}
\end{column}

\begin{column}{0.25\textwidth}
\begin{block}{Vlen}
\vspace*{-0.4cm}
{ \tiny
\begin{verbatim}
netcdf vlens_example {
types:
  compound obs_t {
    float pressure ;
    float temperature ;
    float salinity ;
  }; // obs_t
  obs_t(*) some_obs_t ;
  compound profile_t {
    float latitude ;
    float longitude ;
    int time ;
    some_obs_t obs ;
  }; // profile_t
  profile_t(*) some_profiles_t ;
  compound track_t {
    string id ;
    string description ;
    some_profiles_t profiles ;
  }; // track_t
dimensions:
  tracks = 42 ;
variables:
  track_t cruise(tracks) ;
data:
}
\end{verbatim}
}
\end{block}
\end{column}

\begin{column}{0.37\textwidth}
\begin{block}{Compound}
\vspace*{-0.4cm}
{ \tiny
\begin{verbatim}
netcdf nested_compound_example {
types:
  compound wind_vector_t {
    float eastward ;
    float northward ;
    }
  compound ob_t {
      int station_id ;
      double time ;
      float temperature ;
      float pressure ;
      wind_vector_t wind ;
  }
dimensions:
    stations = unlimited ;
variables:
    ob_t obs(stations) ;
data:
    obs = {42, 0.0, 20.5, 950.0, {2.5, 3.5}};
}
\end{verbatim}
}
\vspace*{-0.4cm}
\end{block}
\end{column}

\end{columns}

\end{frame}

\begin{frame}[fragile]{The NetCDF-4 Enhanced Data Model -- CDL Files}

\begin{columns}

\begin{column}{0.45\textwidth}
\begin{block}{Enum}
\vspace*{-0.4cm}
{ \tiny
\begin{verbatim}
netcdf enums_example {
types:
  byte enum cloud_t {Clear = 0, Cumulonimbus = 1,
      Stratus = 2, Stratocumulus = 3, Cumulus = 4,
      Altostratus = 5, Nimbostratus = 6, Altocumulus = 7,
      Cirrostratus = 8, Cirrocumulus = 9, Cirrus = 10,
      Missing = 127} ;
dimensions:
  time = UNLIMITED ; // (5 currently)
variables:
  cloud_t primary_cloud(time) ;
    cloud_t primary_cloud:_FillValue = Missing ;
data:
 primary_cloud = Clear, Stratus, Clear, Cumulonimbus, _ ;
}
\end{verbatim}
}
\vspace*{-0.4cm}
\end{block}
\end{column}

\begin{column}{0.5\textwidth}
\begin{block}{Opaque}
\vspace*{-0.4cm}
{ \tiny
\begin{verbatim}
netcdf opaque {
types:
  opaque(11) raw_obs_t ;
dimensions:
  time = 5 ;
variables:
  raw_obs_t raw_obs(time) ;
    raw_obs_t raw_obs:_FillValue = 0XCAFEBABECAFEBABECAFEBA ;
data:
 raw_obs = 0X0102030405060708090A0B, 0XAABBCCDDEEFFEEDDCCBBAA,
    0XFFFFFFFFFFFFFFFFFFFFFF, _, 0XCF0DEFACED0CAFE0FACADE ;
}
\end{verbatim}
}
\vspace*{-0.4cm}
\end{block}
\end{column}

\end{columns}

\end{frame}

\begin{frame}[fragile]{NetCDF Library Architecture}

\begin{center}
\begin{tabular}{ccc}
\includegraphics[scale=0.3]{fig/netcdf-architecture}
& $\qquad$ &
\raisebox{3cm}{\includegraphics[scale=0.5]{fig/netcdf-architecture2}}
\end{tabular}
\end{center}

\end{frame}

\subsection{Best Practices for Writing NetCDF Files}

\begin{frame}[fragile]{Experience-based ``Best Practices'' for Writing NetCDF Files}

    \begin{itemize}
    \setlength\itemsep{0.4cm}

        \item	Conventions
        \begin{itemize}
          \item Developers should be familiar with and use existing NetCDF conventions.
        \end{itemize}

        \item	Coordinate systems
        \begin{itemize}
          \item Spatial and temporal location of data are supported by use of coordinate systems.
        \end{itemize}

        \item	Variable grouping
        \begin{itemize}
          \item How you group data into variables can determine whether common analysis and visualisation software can effectively use the data.
        \end{itemize}

        \item	Variable attributes
        \begin{itemize}
          \item Conventional variable attributes supply necessary metadata.
        \end{itemize}

    \end{itemize}

\nocite{netcdf}

\end{frame}

\begin{frame}[fragile]{Experience-based ``Best Practices'' for Writing NetCDF Files}

    \begin{itemize}
    \setlength\itemsep{0.5cm}

        \item	Strings and character variables
        \begin{itemize}
          \item Use character data properly for representing text strings.
        \end{itemize}

        \item Calendar date and time
        \begin{itemize}
          \item Represent calendar dates and times with standards and conventions.
        \end{itemize}

        \item	Packed data values
        \begin{itemize}
          \item Conventions for packing numeric data to save space have some subtleties.
        \end{itemize}

        \item Missing data values
        \begin{itemize}
          \item To indicate that data values are missing, invalid, or not written, special values are conventionally used.
        \end{itemize}

    \end{itemize}

\nocite{netcdf}

\end{frame}

\section{Parallel I/O}
\sectionIntro
\label{sec:pio}

\begin{frame}[fragile]{Parallel I/O}

\begin{itemize}
\setlength\itemsep{0.2cm}

  \item Parallel I/O allows each processor in a multi-processor system to read and write data from multiple processes to a common file independently.

  \begin{center}
  \includegraphics[scale=0.5]{fig/pnetcdf}
  \end{center}

  \item Data-intensive scientific applications use parallel I/O software to access files.

  \item In HPC, increasing demands in the I/O system can cause bottlenecks. Parallel I/O plays a fundamental role to balance the fast increase in computational power and the progress of processor architectures.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Parallel I/O in NetCDF-4}

\begin{itemize}
\setlength\itemsep{0.6cm}

  \item NetCDF-4 provides parallel file access to both classic and NetCDF-4/HDF5 files.

  \item The parallel I/O to classic files is achieved through PNetCDF while the parallel I/O to NetCDF-4 files is through the HDF5 library.

  \item NetCDF-4 exposes the parallel I/O features of HDF5.
    \begin{itemize}
    \item HDF5 provides easy-to-use parallel I/O feature.
    \end{itemize}

  \item Parallel NetCDF uses MPI I/O to perform parallel I/O. It is a complete rewrite of the core C library using MPI I/O instead of POSIX.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Using Parallel I/O in NetCDF-4}

\begin{itemize}

  \item Functions \verb|nc_create_par| and \verb|nc_open_par| are used to create/open NetCDF files.

\end{itemize}

\vspace*{-0.3cm}

\begin{columns}
\begin{column}{0.45\textwidth}
\begin{block}{}
\vspace*{-0.3cm}
{ \tiny
\begin{verbatim}
EXTERNL int
nc_create_par(const char *path, int cmode, MPI_Comm comm,
               MPI_Info info, int *ncidp);
\end{verbatim}
}
\vspace*{-0.3cm}
\end{block}
\end{column}

\begin{column}{0.45\textwidth}
\begin{block}{}
\vspace*{-0.3cm}
{ \tiny
\begin{verbatim}
EXTERNL int
nc_open_par(const char *path, int mode, MPI_Comm comm,
             MPI_Info info, int *ncidp);
\end{verbatim}
}
\vspace*{-0.3cm}
\end{block}
\end{column}
\end{columns}

\vspace*{0.3cm}

  \begin{itemize}
  \setlength\itemsep{0.3cm}

  \item The files they open are normal NetCDF-4/HDF5 files, but these functions also take MPI parameters.

  \item The parallel access associated with these functions is not a characteristic of the data file, but the way it was opened. The data file is the same, but using the parallel \verb|open/create| function allows parallel I/O to take place.

\end{itemize}

\end{frame}

\begin{frame}[fragile]{Collective and Independent Operations with Parallel I/O}

\begin{itemize}
\setlength\itemsep{0.3cm}

  \item In MPI programs, I/O may be collective or independent.

    \begin{itemize}
      \item Collective: It must be done by all processes at the same time.
      \item Independent: It can be done by any process at any time.
    \end{itemize}

  \item All NetCDF metadata writing operations are collective. All creation of dimensions, variables, attributes, types, and groups are done by all processes at the same time.

  \item Reading and writing data (ex. calls to \verb|nc_put_var_int| and \verb|nc_get_var_int|) may be independent (the default) or collective. To write into a variable collectively, call the \verb|nc_var_par_access| function.

\end{itemize}

\vspace*{-0.3cm}

\begin{columns}
\begin{column}{0.45\textwidth}
\begin{block}{}
\vspace*{-0.3cm}
{ \tiny
\begin{verbatim}
EXTERNL int
nc_var_par_access(int ncid, int varid, int par_access);
\end{verbatim}
}
\vspace*{-0.3cm}
\end{block}
\end{column}

\begin{column}{0.35\textwidth}
\begin{block}{}
\vspace*{-0.3cm}
{ \tiny
\begin{verbatim}
/* Use these with nc_var_par_access(). */
#define NC_INDEPENDENT 0
#define NC_COLLECTIVE 1
\end{verbatim}
}
\vspace*{-0.3cm}
\end{block}
\end{column}
\end{columns}

\end{frame}

\begin{frame}[fragile]{Converting NetCDF-4 to Parallel NetCDF-4}

\begin{center}
\includegraphics[scale=0.42]{fig/netcdf-par1}
\end{center}

\end{frame}

\begin{frame}[fragile]{Converting NetCDF-4 to Parallel NetCDF-4}

\begin{center}
\includegraphics[scale=0.42]{fig/netcdf-par2}
\end{center}

\end{frame}

\begin{frame}[fragile]{Converting NetCDF-4 to Parallel NetCDF-4}

\begin{center}
\includegraphics[scale=0.42]{fig/netcdf-par3}
\end{center}

\end{frame}

\subsection{Examples of Performance}

\begin{frame}[fragile]{Examples of Performance -- POSIX $\times$ MPI-I/O}

\begin{itemize}
\setlength\itemsep{0.5cm}

\item Two programs using POSIX to write a 16k file.

  \begin{itemize}
    \item The first program writes \textbf{every byte} with one I/O call.
    \item The second program writes \textbf{all bytes} with one I/O call.
  \end{itemize}

\item One program using MPI-I/O to write a 16k file.

  \begin{itemize}
    \item The program writes \textbf{all bytes} with one I/O call.
  \end{itemize}

\item Codes are available at:

  \begin{itemize}
    \item \url{https://github.com/ESiWACE/io-training/tree/master/POSIX}
    \item Also available in the Virtual Machine.
  \end{itemize}

\end{itemize}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.6]{fig/prog-posix1}
\end{center}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.6]{fig/prog-posix2}
\end{center}

\end{frame}

\begin{frame}[fragile]{}

\begin{center}
\includegraphics[scale=0.6]{fig/prog-mpi}
\end{center}

\end{frame}

\begin{frame}[fragile]{Examples of Performance -- POSIX $\times$ MPI-I/O}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item \textbf{Best values measured in a standard laptop (Intel Core i5).}
  \begin{itemize}
    \item Similar order of magnitude in the VM.
  \end{itemize}

\item Two programs using POSIX to write a 16k file.

  \begin{itemize}
  \setlength\itemsep{0.2cm}

    \item The first program writes every byte with one I/O call.
    \begin{itemize}
      \item Measured \onslide<2->{2.760475e-02}s at \onslide<3->{0.142} MiB/s.
    \end{itemize}

    \item The first program writes all bytes with one I/O call.
    \begin{itemize}
      \item Measured \onslide<2->{3.928800e-05}s at \onslide<4->{99.426} MiB/s.
    \end{itemize}

  \end{itemize}

\item One program using MPI-I/O to write a 16k file.

  \begin{itemize}

  \item The program writes all bytes with one I/O call.
  \begin{itemize}
    \item Measured \onslide<2->{1.160006e-07}s at \onslide<5->{33674.397} MiB/s.
  \end{itemize}

  \end{itemize}

\end{itemize}

\end{frame}

\section{Research Activities}
\sectionIntro
\label{sec:res}

\subsection{WP4}

\begin{frame}[fragile]{ESiWACE -- Work Package 4}

\begin{columns}

\begin{column}{0.7\textwidth}

\begin{block}{Objectives}
\begin{itemize}
\setlength\itemsep{0.5cm}
  \item Support data reduction in ensembles by providing tools to carry out ensemble statistics ``in-flight'' and compress ensemble members.
  \item Hide complexity of multiple-storage tiers (middleware between NetCDF and storage) with industrial prototype backends.
  \item Deliver portable workflow support for manual migration of semantically important content between disk, tape, and object stores.
\end{itemize}
\end{block}

\end{column}

\begin{column}{0.3\textwidth}
\begin{center}
\raisebox{0.5cm}{\includegraphics[scale=0.5]{fig/wp4}}
\end{center}
\end{column}

\end{columns}

\end{frame}

\subsection{NGI}

\begin{frame}[fragile]{Next Generation Interfaces (NGI)}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item Towards a new I/O stack considering:

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item User metadata and workflows as first-class citizens
    \item Smart hardware and software components
    \item Liquid-Computing: Smart-placement of computing
    \item Self-aware instead of unconscious
    \item Improving over time (self-learning, hardware upgrades)
  \end{itemize}

\item Why do we need a new domain-independent API?

  \begin{itemize}
  \setlength\itemsep{0.2cm}
    \item Other domains have similar issues
    \item It is a hard problem approached by countless approaches
    \item Harness RD\&E effort across domains
  \end{itemize}

\end{itemize}

\end{frame}

\subsection{Compression}

\begin{frame}[fragile]{Smart Compression}

\begin{itemize}
\setlength\itemsep{0.4cm}

\item The main purpose of compression methods is to shrink data and to save storage space.

\item Compression methods also possess a huge potential to reduce the gap between computational power and I/O performance.

  \begin{itemize}
    \item Often, after compression, less data has to be moved.
  \end{itemize}

\item Many modern file formats, in particular HDF5 and NetCDF-4, provide native support for compression.

  \begin{itemize}
    \item Beneficial in climate science, where data amounts are huge and are growing constantly.
  \end{itemize}

\item The compression algorithms used in HDF5 and NetCDF-4 are lossless and do not meet the requirements of climate science to full extent.

\end{itemize}

\end{frame}

\begin{comment}

\begin{frame}[fragile]{I/O Stack}

\begin{center}
\includegraphics[scale=0.7]{fig/stack3}
\end{center}

\end{frame}

\begin{frame}[fragile]{Previous Learning Objectives}

\begin{itemize}

    \item Describe the general layers involved in I/O on a supercomputer
    \item Analyse the implications of parallel I/O on application efficiency
    \item Identify typical I/O performance issues and their causes
    \item Design a data model for NetCDF/CF
    \item Read, analyse, and write NetCDF files in a metadata-aware manner
    \item Visualise and regrid field constructs within NetCDF

\end{itemize}

\end{frame}

\end{comment}

\begin{frame}[allowframebreaks]{Bibliography}

{

\tiny

\bibliographystyle{alpha}
\bibliography{io}

}

\end{frame}

\acknowledgement

\appendix

\begin{frame}[fragile]{}

{ \huge \color{EsiBlue}{Appendix}}

\end{frame}

\section{ESDM}

\begin{frame}[fragile]{Earth-System Data Middleware (ESDM)}

\begin{block}{A transitional approach towards a vision for I/O addressing}
\begin{itemize}
\setlength\itemsep{0.1cm}
  \item Scalable data management practice
  \item The inhomogeneous storage stack
  \item Suboptimal performance and performance portability
  \item Data conversion/merging
\end{itemize}
\end{block}

\begin{block}{Design goals of the Earth-System Data Middleware}
\begin{enumerate}
\setlength\itemsep{0.1cm}
  \item Relaxed access semantics, tailored to scientific data generation
  \item Site-specific (optimised) data layout schemes
  \item Ease of use and deploy a particular configuration
  \item Enable a configurable namespace based on scientific metadata
\end{enumerate}
\end{block}

\end{frame}

\begin{frame}[fragile]{ESDM -- Architecture}

\begin{block}{\textbf{Key Concept}: Decouple data localisation decisions from science}
\begin{itemize}
\setlength\itemsep{0.2cm}
  \item Middleware utilises layout component to make placement decisions
  \item Applications work through existing API
  \item Data is then written/read efficiently; potential for optimisation inside library
\end{itemize}
\end{block}

\begin{center}
\includegraphics[scale=0.6]{fig/esdm-arch}
\end{center}

\end{frame}

\begin{frame}[fragile]{ESDM -- Benefits}

\begin{itemize}
\setlength\itemsep{0.4cm}
  \item Expose/access the same data via different APIs
  \item Independent and lock-free writes from parallel applications
  \item No fixed storage layout
  \item Less performance tuning from users needed
  \item Exploit characteristics of different storage technology
  \item Multiple layouts of one data structure optimise access patterns
  \item Flexible namespace (similar to MP3 library)
\end{itemize}

\end{frame}

\begin{frame}[fragile]{ESDM Architecture}

\begin{center}
\includegraphics[scale=0.35]{fig/esdm-arch1}
\end{center}

\end{frame}

\begin{frame}[fragile]{ESDM Architecture and Interactions}

\begin{center}
\includegraphics[scale=0.3]{fig/esdm-arch2}
\end{center}

\end{frame}

\begin{frame}[fragile]{Scientific Compression Library (SCIL)}

\begin{itemize}
\setlength\itemsep{0.2cm}
    \item In ESiWACE, SCIL is integrated into ESDM to allow scientists to specify the data properties on datasets.

    \begin{itemize}
    \setlength\itemsep{0.2cm}
        \item Developed in the AIMES Project\footnote{Advanced Computation and I/O Methods for Earth-System Simulations (AIMES) Project.}.
        \item The main purpose of SCIL is compression/decompression of scientific data, especially, of climate modeling data.
        \item Uses different third party compression libraries as well as specifically developed lossy and lossless compression methods.
        \item Separates concern of data accuracy and choice of algorithms.
        \item Users specify necessary accuracy and performance parameters.
        \item Metacompression library makes the choice of algorithms.
        \item Supports new algorithms.
    \end{itemize}

\end{itemize}

\end{frame}

\end{document}
